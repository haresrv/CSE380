{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "p1h_5ryAGECe",
    "outputId": "21feac93-247d-4a73-c233-6de9c4a22e7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XUfa6DIZHv7H"
   },
   "source": [
    "# Model 1: One-Word-In, One-Word-Out Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UM5HBhZxGQoI"
   },
   "outputs": [],
   "source": [
    "# generate a sequence from the model\n",
    "def generate_seq(model, tokenizer, seed_text, n_words):\n",
    "\tin_text, result = seed_text, seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\tencoded = array(encoded)\n",
    "\t\t# predict a word in the vocabulary\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text, result = out_word, result + ' ' + out_word\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7mDk-s3GWn_"
   },
   "outputs": [],
   "source": [
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "\t\tTo fetch a pail of water\\n\n",
    "\t\tJack fell down and broke his crown\\n\n",
    "\t\tAnd Jill came tumbling after\\n \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdX5LrGZGY_m"
   },
   "outputs": [],
   "source": [
    "# integer encode text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "9q4yZT1RGbVQ",
    "outputId": "92a7442c-b212-4649-a5fc-8c86b8f10912"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 2,\n",
       " 14,\n",
       " 15,\n",
       " 1,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 1,\n",
       " 3,\n",
       " 19,\n",
       " 20,\n",
       " 21]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YGCWx48RGcq0",
    "outputId": "fc8f0975-2829-4a21-cf8a-4c22b97a3d25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 22\n"
     ]
    }
   ],
   "source": [
    "# determine the vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g5qWJWqBGw-S",
    "outputId": "99780204-9362-4743-e999-8fb1301b8e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 24\n"
     ]
    }
   ],
   "source": [
    "# create word -> word sequences\n",
    "sequences = list()\n",
    "for i in range(1, len(encoded)):\n",
    "\tsequence = encoded[i-1:i+1]\n",
    "\tsequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "oJqi6uI0G0EN",
    "outputId": "cc10ebf1-cc68-4c22-9d48-5d112564aeb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1],\n",
       " [1, 3],\n",
       " [3, 4],\n",
       " [4, 5],\n",
       " [5, 6],\n",
       " [6, 7],\n",
       " [7, 8],\n",
       " [8, 9],\n",
       " [9, 10],\n",
       " [10, 11],\n",
       " [11, 12],\n",
       " [12, 13],\n",
       " [13, 2],\n",
       " [2, 14],\n",
       " [14, 15],\n",
       " [15, 1],\n",
       " [1, 16],\n",
       " [16, 17],\n",
       " [17, 18],\n",
       " [18, 1],\n",
       " [1, 3],\n",
       " [3, 19],\n",
       " [19, 20],\n",
       " [20, 21]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mn-sF-rXG2Uu"
   },
   "outputs": [],
   "source": [
    "# split into X and y elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,0],sequences[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "zGLqlomJQ-kM",
    "outputId": "0383d942-55f8-43f1-c052-5c55fefc6e47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  1,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  2, 14, 15,  1,\n",
       "       16, 17, 18,  1,  3, 19, 20])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8llgnWx1Q_FF",
    "outputId": "3cd64382-f484-4c43-bc81-6baf71f68f73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  2, 14, 15,  1, 16,\n",
       "       17, 18,  1,  3, 19, 20, 21])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i7kA4oZoG7Wv"
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "6s6rSUViG9s2",
    "outputId": "5a7e4e1c-4eb8-4b96-837e-31dd398bac3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1, 10)             220       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 22)                1122      \n",
      "=================================================================\n",
      "Total params: 13,542\n",
      "Trainable params: 13,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "KyY-1PVeHAbR",
    "outputId": "85f0e62c-e18b-4aae-f7fd-39dc385e9779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ghp2f6FrHGNq",
    "outputId": "cf5f6b02-1a9f-4f51-855d-1869bfde1510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/500\n",
      " - 2s - loss: 3.0918 - acc: 0.0417\n",
      "Epoch 2/500\n",
      " - 0s - loss: 3.0910 - acc: 0.0417\n",
      "Epoch 3/500\n",
      " - 0s - loss: 3.0902 - acc: 0.0833\n",
      "Epoch 4/500\n",
      " - 0s - loss: 3.0894 - acc: 0.1250\n",
      "Epoch 5/500\n",
      " - 0s - loss: 3.0885 - acc: 0.1667\n",
      "Epoch 6/500\n",
      " - 0s - loss: 3.0877 - acc: 0.2083\n",
      "Epoch 7/500\n",
      " - 0s - loss: 3.0869 - acc: 0.2083\n",
      "Epoch 8/500\n",
      " - 0s - loss: 3.0861 - acc: 0.2083\n",
      "Epoch 9/500\n",
      " - 0s - loss: 3.0853 - acc: 0.2083\n",
      "Epoch 10/500\n",
      " - 0s - loss: 3.0844 - acc: 0.2083\n",
      "Epoch 11/500\n",
      " - 0s - loss: 3.0836 - acc: 0.2083\n",
      "Epoch 12/500\n",
      " - 0s - loss: 3.0828 - acc: 0.2083\n",
      "Epoch 13/500\n",
      " - 0s - loss: 3.0819 - acc: 0.2083\n",
      "Epoch 14/500\n",
      " - 0s - loss: 3.0811 - acc: 0.2083\n",
      "Epoch 15/500\n",
      " - 0s - loss: 3.0802 - acc: 0.2083\n",
      "Epoch 16/500\n",
      " - 0s - loss: 3.0793 - acc: 0.2083\n",
      "Epoch 17/500\n",
      " - 0s - loss: 3.0784 - acc: 0.2083\n",
      "Epoch 18/500\n",
      " - 0s - loss: 3.0775 - acc: 0.2083\n",
      "Epoch 19/500\n",
      " - 0s - loss: 3.0766 - acc: 0.2083\n",
      "Epoch 20/500\n",
      " - 0s - loss: 3.0756 - acc: 0.2083\n",
      "Epoch 21/500\n",
      " - 0s - loss: 3.0746 - acc: 0.2083\n",
      "Epoch 22/500\n",
      " - 0s - loss: 3.0736 - acc: 0.2083\n",
      "Epoch 23/500\n",
      " - 0s - loss: 3.0726 - acc: 0.2083\n",
      "Epoch 24/500\n",
      " - 0s - loss: 3.0716 - acc: 0.2083\n",
      "Epoch 25/500\n",
      " - 0s - loss: 3.0705 - acc: 0.2083\n",
      "Epoch 26/500\n",
      " - 0s - loss: 3.0695 - acc: 0.2083\n",
      "Epoch 27/500\n",
      " - 0s - loss: 3.0684 - acc: 0.2083\n",
      "Epoch 28/500\n",
      " - 0s - loss: 3.0672 - acc: 0.2083\n",
      "Epoch 29/500\n",
      " - 0s - loss: 3.0661 - acc: 0.2083\n",
      "Epoch 30/500\n",
      " - 0s - loss: 3.0649 - acc: 0.2083\n",
      "Epoch 31/500\n",
      " - 0s - loss: 3.0637 - acc: 0.2083\n",
      "Epoch 32/500\n",
      " - 0s - loss: 3.0624 - acc: 0.2083\n",
      "Epoch 33/500\n",
      " - 0s - loss: 3.0611 - acc: 0.2083\n",
      "Epoch 34/500\n",
      " - 0s - loss: 3.0598 - acc: 0.2083\n",
      "Epoch 35/500\n",
      " - 0s - loss: 3.0584 - acc: 0.2083\n",
      "Epoch 36/500\n",
      " - 0s - loss: 3.0570 - acc: 0.2083\n",
      "Epoch 37/500\n",
      " - 0s - loss: 3.0556 - acc: 0.2083\n",
      "Epoch 38/500\n",
      " - 0s - loss: 3.0541 - acc: 0.2083\n",
      "Epoch 39/500\n",
      " - 0s - loss: 3.0526 - acc: 0.2083\n",
      "Epoch 40/500\n",
      " - 0s - loss: 3.0511 - acc: 0.2083\n",
      "Epoch 41/500\n",
      " - 0s - loss: 3.0495 - acc: 0.2083\n",
      "Epoch 42/500\n",
      " - 0s - loss: 3.0478 - acc: 0.2083\n",
      "Epoch 43/500\n",
      " - 0s - loss: 3.0461 - acc: 0.2083\n",
      "Epoch 44/500\n",
      " - 0s - loss: 3.0444 - acc: 0.2083\n",
      "Epoch 45/500\n",
      " - 0s - loss: 3.0426 - acc: 0.2083\n",
      "Epoch 46/500\n",
      " - 0s - loss: 3.0408 - acc: 0.2083\n",
      "Epoch 47/500\n",
      " - 0s - loss: 3.0389 - acc: 0.2083\n",
      "Epoch 48/500\n",
      " - 0s - loss: 3.0369 - acc: 0.2083\n",
      "Epoch 49/500\n",
      " - 0s - loss: 3.0349 - acc: 0.2083\n",
      "Epoch 50/500\n",
      " - 0s - loss: 3.0329 - acc: 0.2083\n",
      "Epoch 51/500\n",
      " - 0s - loss: 3.0308 - acc: 0.2083\n",
      "Epoch 52/500\n",
      " - 0s - loss: 3.0286 - acc: 0.2083\n",
      "Epoch 53/500\n",
      " - 0s - loss: 3.0264 - acc: 0.2083\n",
      "Epoch 54/500\n",
      " - 0s - loss: 3.0241 - acc: 0.2083\n",
      "Epoch 55/500\n",
      " - 0s - loss: 3.0217 - acc: 0.2083\n",
      "Epoch 56/500\n",
      " - 0s - loss: 3.0193 - acc: 0.2083\n",
      "Epoch 57/500\n",
      " - 0s - loss: 3.0168 - acc: 0.2083\n",
      "Epoch 58/500\n",
      " - 0s - loss: 3.0142 - acc: 0.2083\n",
      "Epoch 59/500\n",
      " - 0s - loss: 3.0116 - acc: 0.2083\n",
      "Epoch 60/500\n",
      " - 0s - loss: 3.0089 - acc: 0.2083\n",
      "Epoch 61/500\n",
      " - 0s - loss: 3.0061 - acc: 0.2083\n",
      "Epoch 62/500\n",
      " - 0s - loss: 3.0032 - acc: 0.2083\n",
      "Epoch 63/500\n",
      " - 0s - loss: 3.0003 - acc: 0.2083\n",
      "Epoch 64/500\n",
      " - 0s - loss: 2.9972 - acc: 0.2083\n",
      "Epoch 65/500\n",
      " - 0s - loss: 2.9941 - acc: 0.2083\n",
      "Epoch 66/500\n",
      " - 0s - loss: 2.9909 - acc: 0.2083\n",
      "Epoch 67/500\n",
      " - 0s - loss: 2.9877 - acc: 0.2083\n",
      "Epoch 68/500\n",
      " - 0s - loss: 2.9843 - acc: 0.2083\n",
      "Epoch 69/500\n",
      " - 0s - loss: 2.9808 - acc: 0.2083\n",
      "Epoch 70/500\n",
      " - 0s - loss: 2.9773 - acc: 0.2083\n",
      "Epoch 71/500\n",
      " - 0s - loss: 2.9736 - acc: 0.2083\n",
      "Epoch 72/500\n",
      " - 0s - loss: 2.9699 - acc: 0.2083\n",
      "Epoch 73/500\n",
      " - 0s - loss: 2.9660 - acc: 0.2083\n",
      "Epoch 74/500\n",
      " - 0s - loss: 2.9621 - acc: 0.2083\n",
      "Epoch 75/500\n",
      " - 0s - loss: 2.9580 - acc: 0.2083\n",
      "Epoch 76/500\n",
      " - 0s - loss: 2.9539 - acc: 0.2083\n",
      "Epoch 77/500\n",
      " - 0s - loss: 2.9496 - acc: 0.2083\n",
      "Epoch 78/500\n",
      " - 0s - loss: 2.9452 - acc: 0.2083\n",
      "Epoch 79/500\n",
      " - 0s - loss: 2.9407 - acc: 0.2083\n",
      "Epoch 80/500\n",
      " - 0s - loss: 2.9361 - acc: 0.2083\n",
      "Epoch 81/500\n",
      " - 0s - loss: 2.9314 - acc: 0.2083\n",
      "Epoch 82/500\n",
      " - 0s - loss: 2.9265 - acc: 0.2083\n",
      "Epoch 83/500\n",
      " - 0s - loss: 2.9215 - acc: 0.2083\n",
      "Epoch 84/500\n",
      " - 0s - loss: 2.9164 - acc: 0.2083\n",
      "Epoch 85/500\n",
      " - 0s - loss: 2.9112 - acc: 0.2083\n",
      "Epoch 86/500\n",
      " - 0s - loss: 2.9058 - acc: 0.2083\n",
      "Epoch 87/500\n",
      " - 0s - loss: 2.9003 - acc: 0.2083\n",
      "Epoch 88/500\n",
      " - 0s - loss: 2.8947 - acc: 0.2083\n",
      "Epoch 89/500\n",
      " - 0s - loss: 2.8889 - acc: 0.2083\n",
      "Epoch 90/500\n",
      " - 0s - loss: 2.8830 - acc: 0.2083\n",
      "Epoch 91/500\n",
      " - 0s - loss: 2.8770 - acc: 0.2083\n",
      "Epoch 92/500\n",
      " - 0s - loss: 2.8708 - acc: 0.2083\n",
      "Epoch 93/500\n",
      " - 0s - loss: 2.8644 - acc: 0.2083\n",
      "Epoch 94/500\n",
      " - 0s - loss: 2.8579 - acc: 0.2083\n",
      "Epoch 95/500\n",
      " - 0s - loss: 2.8513 - acc: 0.2083\n",
      "Epoch 96/500\n",
      " - 0s - loss: 2.8445 - acc: 0.2083\n",
      "Epoch 97/500\n",
      " - 0s - loss: 2.8375 - acc: 0.2083\n",
      "Epoch 98/500\n",
      " - 0s - loss: 2.8304 - acc: 0.2083\n",
      "Epoch 99/500\n",
      " - 0s - loss: 2.8231 - acc: 0.2083\n",
      "Epoch 100/500\n",
      " - 0s - loss: 2.8157 - acc: 0.2083\n",
      "Epoch 101/500\n",
      " - 0s - loss: 2.8081 - acc: 0.2083\n",
      "Epoch 102/500\n",
      " - 0s - loss: 2.8003 - acc: 0.2083\n",
      "Epoch 103/500\n",
      " - 0s - loss: 2.7924 - acc: 0.2083\n",
      "Epoch 104/500\n",
      " - 0s - loss: 2.7843 - acc: 0.2083\n",
      "Epoch 105/500\n",
      " - 0s - loss: 2.7760 - acc: 0.2083\n",
      "Epoch 106/500\n",
      " - 0s - loss: 2.7676 - acc: 0.2083\n",
      "Epoch 107/500\n",
      " - 0s - loss: 2.7590 - acc: 0.2083\n",
      "Epoch 108/500\n",
      " - 0s - loss: 2.7502 - acc: 0.2083\n",
      "Epoch 109/500\n",
      " - 0s - loss: 2.7413 - acc: 0.2083\n",
      "Epoch 110/500\n",
      " - 0s - loss: 2.7321 - acc: 0.2083\n",
      "Epoch 111/500\n",
      " - 0s - loss: 2.7228 - acc: 0.2083\n",
      "Epoch 112/500\n",
      " - 0s - loss: 2.7133 - acc: 0.2083\n",
      "Epoch 113/500\n",
      " - 0s - loss: 2.7037 - acc: 0.2083\n",
      "Epoch 114/500\n",
      " - 0s - loss: 2.6939 - acc: 0.2083\n",
      "Epoch 115/500\n",
      " - 0s - loss: 2.6839 - acc: 0.2083\n",
      "Epoch 116/500\n",
      " - 0s - loss: 2.6737 - acc: 0.2083\n",
      "Epoch 117/500\n",
      " - 0s - loss: 2.6633 - acc: 0.2083\n",
      "Epoch 118/500\n",
      " - 0s - loss: 2.6528 - acc: 0.2083\n",
      "Epoch 119/500\n",
      " - 0s - loss: 2.6420 - acc: 0.2083\n",
      "Epoch 120/500\n",
      " - 0s - loss: 2.6312 - acc: 0.2083\n",
      "Epoch 121/500\n",
      " - 0s - loss: 2.6201 - acc: 0.2083\n",
      "Epoch 122/500\n",
      " - 0s - loss: 2.6088 - acc: 0.2083\n",
      "Epoch 123/500\n",
      " - 0s - loss: 2.5974 - acc: 0.2083\n",
      "Epoch 124/500\n",
      " - 0s - loss: 2.5859 - acc: 0.2083\n",
      "Epoch 125/500\n",
      " - 0s - loss: 2.5741 - acc: 0.2500\n",
      "Epoch 126/500\n",
      " - 0s - loss: 2.5622 - acc: 0.2500\n",
      "Epoch 127/500\n",
      " - 0s - loss: 2.5501 - acc: 0.2500\n",
      "Epoch 128/500\n",
      " - 0s - loss: 2.5378 - acc: 0.2500\n",
      "Epoch 129/500\n",
      " - 0s - loss: 2.5254 - acc: 0.2500\n",
      "Epoch 130/500\n",
      " - 0s - loss: 2.5129 - acc: 0.2500\n",
      "Epoch 131/500\n",
      " - 0s - loss: 2.5001 - acc: 0.2500\n",
      "Epoch 132/500\n",
      " - 0s - loss: 2.4872 - acc: 0.2500\n",
      "Epoch 133/500\n",
      " - 0s - loss: 2.4742 - acc: 0.2500\n",
      "Epoch 134/500\n",
      " - 0s - loss: 2.4610 - acc: 0.2500\n",
      "Epoch 135/500\n",
      " - 0s - loss: 2.4477 - acc: 0.2500\n",
      "Epoch 136/500\n",
      " - 0s - loss: 2.4342 - acc: 0.2500\n",
      "Epoch 137/500\n",
      " - 0s - loss: 2.4206 - acc: 0.2500\n",
      "Epoch 138/500\n",
      " - 0s - loss: 2.4069 - acc: 0.2500\n",
      "Epoch 139/500\n",
      " - 0s - loss: 2.3930 - acc: 0.2500\n",
      "Epoch 140/500\n",
      " - 0s - loss: 2.3790 - acc: 0.2500\n",
      "Epoch 141/500\n",
      " - 0s - loss: 2.3649 - acc: 0.2500\n",
      "Epoch 142/500\n",
      " - 0s - loss: 2.3507 - acc: 0.2500\n",
      "Epoch 143/500\n",
      " - 0s - loss: 2.3363 - acc: 0.2500\n",
      "Epoch 144/500\n",
      " - 0s - loss: 2.3219 - acc: 0.2917\n",
      "Epoch 145/500\n",
      " - 0s - loss: 2.3073 - acc: 0.3750\n",
      "Epoch 146/500\n",
      " - 0s - loss: 2.2927 - acc: 0.3750\n",
      "Epoch 147/500\n",
      " - 0s - loss: 2.2780 - acc: 0.3750\n",
      "Epoch 148/500\n",
      " - 0s - loss: 2.2631 - acc: 0.3750\n",
      "Epoch 149/500\n",
      " - 0s - loss: 2.2482 - acc: 0.3750\n",
      "Epoch 150/500\n",
      " - 0s - loss: 2.2332 - acc: 0.3750\n",
      "Epoch 151/500\n",
      " - 0s - loss: 2.2181 - acc: 0.3750\n",
      "Epoch 152/500\n",
      " - 0s - loss: 2.2030 - acc: 0.5000\n",
      "Epoch 153/500\n",
      " - 0s - loss: 2.1878 - acc: 0.5000\n",
      "Epoch 154/500\n",
      " - 0s - loss: 2.1725 - acc: 0.5000\n",
      "Epoch 155/500\n",
      " - 0s - loss: 2.1572 - acc: 0.5000\n",
      "Epoch 156/500\n",
      " - 0s - loss: 2.1418 - acc: 0.5000\n",
      "Epoch 157/500\n",
      " - 0s - loss: 2.1264 - acc: 0.5000\n",
      "Epoch 158/500\n",
      " - 0s - loss: 2.1109 - acc: 0.5000\n",
      "Epoch 159/500\n",
      " - 0s - loss: 2.0954 - acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/500\n",
      " - 0s - loss: 2.0799 - acc: 0.5417\n",
      "Epoch 161/500\n",
      " - 0s - loss: 2.0643 - acc: 0.5417\n",
      "Epoch 162/500\n",
      " - 0s - loss: 2.0487 - acc: 0.5417\n",
      "Epoch 163/500\n",
      " - 0s - loss: 2.0331 - acc: 0.6250\n",
      "Epoch 164/500\n",
      " - 0s - loss: 2.0175 - acc: 0.6250\n",
      "Epoch 165/500\n",
      " - 0s - loss: 2.0018 - acc: 0.6250\n",
      "Epoch 166/500\n",
      " - 0s - loss: 1.9861 - acc: 0.6250\n",
      "Epoch 167/500\n",
      " - 0s - loss: 1.9705 - acc: 0.6250\n",
      "Epoch 168/500\n",
      " - 0s - loss: 1.9548 - acc: 0.6250\n",
      "Epoch 169/500\n",
      " - 0s - loss: 1.9391 - acc: 0.6250\n",
      "Epoch 170/500\n",
      " - 0s - loss: 1.9234 - acc: 0.6250\n",
      "Epoch 171/500\n",
      " - 0s - loss: 1.9078 - acc: 0.6250\n",
      "Epoch 172/500\n",
      " - 0s - loss: 1.8921 - acc: 0.6250\n",
      "Epoch 173/500\n",
      " - 0s - loss: 1.8764 - acc: 0.6250\n",
      "Epoch 174/500\n",
      " - 0s - loss: 1.8608 - acc: 0.6250\n",
      "Epoch 175/500\n",
      " - 0s - loss: 1.8451 - acc: 0.6250\n",
      "Epoch 176/500\n",
      " - 0s - loss: 1.8295 - acc: 0.6667\n",
      "Epoch 177/500\n",
      " - 0s - loss: 1.8139 - acc: 0.6667\n",
      "Epoch 178/500\n",
      " - 0s - loss: 1.7983 - acc: 0.6667\n",
      "Epoch 179/500\n",
      " - 0s - loss: 1.7827 - acc: 0.6667\n",
      "Epoch 180/500\n",
      " - 0s - loss: 1.7672 - acc: 0.6667\n",
      "Epoch 181/500\n",
      " - 0s - loss: 1.7517 - acc: 0.6667\n",
      "Epoch 182/500\n",
      " - 0s - loss: 1.7362 - acc: 0.6667\n",
      "Epoch 183/500\n",
      " - 0s - loss: 1.7207 - acc: 0.6667\n",
      "Epoch 184/500\n",
      " - 0s - loss: 1.7053 - acc: 0.6667\n",
      "Epoch 185/500\n",
      " - 0s - loss: 1.6899 - acc: 0.6667\n",
      "Epoch 186/500\n",
      " - 0s - loss: 1.6745 - acc: 0.6667\n",
      "Epoch 187/500\n",
      " - 0s - loss: 1.6591 - acc: 0.7083\n",
      "Epoch 188/500\n",
      " - 0s - loss: 1.6438 - acc: 0.7083\n",
      "Epoch 189/500\n",
      " - 0s - loss: 1.6286 - acc: 0.7083\n",
      "Epoch 190/500\n",
      " - 0s - loss: 1.6133 - acc: 0.7083\n",
      "Epoch 191/500\n",
      " - 0s - loss: 1.5982 - acc: 0.7083\n",
      "Epoch 192/500\n",
      " - 0s - loss: 1.5830 - acc: 0.7500\n",
      "Epoch 193/500\n",
      " - 0s - loss: 1.5679 - acc: 0.7500\n",
      "Epoch 194/500\n",
      " - 0s - loss: 1.5528 - acc: 0.7500\n",
      "Epoch 195/500\n",
      " - 0s - loss: 1.5378 - acc: 0.7500\n",
      "Epoch 196/500\n",
      " - 0s - loss: 1.5228 - acc: 0.7500\n",
      "Epoch 197/500\n",
      " - 0s - loss: 1.5079 - acc: 0.7500\n",
      "Epoch 198/500\n",
      " - 0s - loss: 1.4930 - acc: 0.7500\n",
      "Epoch 199/500\n",
      " - 0s - loss: 1.4782 - acc: 0.7500\n",
      "Epoch 200/500\n",
      " - 0s - loss: 1.4635 - acc: 0.7500\n",
      "Epoch 201/500\n",
      " - 0s - loss: 1.4487 - acc: 0.7500\n",
      "Epoch 202/500\n",
      " - 0s - loss: 1.4341 - acc: 0.7500\n",
      "Epoch 203/500\n",
      " - 0s - loss: 1.4195 - acc: 0.7917\n",
      "Epoch 204/500\n",
      " - 0s - loss: 1.4049 - acc: 0.8333\n",
      "Epoch 205/500\n",
      " - 0s - loss: 1.3905 - acc: 0.8333\n",
      "Epoch 206/500\n",
      " - 0s - loss: 1.3761 - acc: 0.8333\n",
      "Epoch 207/500\n",
      " - 0s - loss: 1.3617 - acc: 0.8333\n",
      "Epoch 208/500\n",
      " - 0s - loss: 1.3474 - acc: 0.8333\n",
      "Epoch 209/500\n",
      " - 0s - loss: 1.3332 - acc: 0.8333\n",
      "Epoch 210/500\n",
      " - 0s - loss: 1.3191 - acc: 0.8333\n",
      "Epoch 211/500\n",
      " - 0s - loss: 1.3050 - acc: 0.8333\n",
      "Epoch 212/500\n",
      " - 0s - loss: 1.2910 - acc: 0.8333\n",
      "Epoch 213/500\n",
      " - 0s - loss: 1.2771 - acc: 0.8333\n",
      "Epoch 214/500\n",
      " - 0s - loss: 1.2632 - acc: 0.8333\n",
      "Epoch 215/500\n",
      " - 0s - loss: 1.2495 - acc: 0.8333\n",
      "Epoch 216/500\n",
      " - 0s - loss: 1.2358 - acc: 0.8333\n",
      "Epoch 217/500\n",
      " - 0s - loss: 1.2222 - acc: 0.8333\n",
      "Epoch 218/500\n",
      " - 0s - loss: 1.2087 - acc: 0.8333\n",
      "Epoch 219/500\n",
      " - 0s - loss: 1.1952 - acc: 0.8750\n",
      "Epoch 220/500\n",
      " - 0s - loss: 1.1819 - acc: 0.8750\n",
      "Epoch 221/500\n",
      " - 0s - loss: 1.1686 - acc: 0.8750\n",
      "Epoch 222/500\n",
      " - 0s - loss: 1.1555 - acc: 0.8750\n",
      "Epoch 223/500\n",
      " - 0s - loss: 1.1424 - acc: 0.8750\n",
      "Epoch 224/500\n",
      " - 0s - loss: 1.1294 - acc: 0.8750\n",
      "Epoch 225/500\n",
      " - 0s - loss: 1.1166 - acc: 0.8750\n",
      "Epoch 226/500\n",
      " - 0s - loss: 1.1038 - acc: 0.8750\n",
      "Epoch 227/500\n",
      " - 0s - loss: 1.0911 - acc: 0.8750\n",
      "Epoch 228/500\n",
      " - 0s - loss: 1.0785 - acc: 0.8750\n",
      "Epoch 229/500\n",
      " - 0s - loss: 1.0661 - acc: 0.8750\n",
      "Epoch 230/500\n",
      " - 0s - loss: 1.0537 - acc: 0.8750\n",
      "Epoch 231/500\n",
      " - 0s - loss: 1.0415 - acc: 0.8750\n",
      "Epoch 232/500\n",
      " - 0s - loss: 1.0293 - acc: 0.8750\n",
      "Epoch 233/500\n",
      " - 0s - loss: 1.0173 - acc: 0.8750\n",
      "Epoch 234/500\n",
      " - 0s - loss: 1.0054 - acc: 0.8750\n",
      "Epoch 235/500\n",
      " - 0s - loss: 0.9936 - acc: 0.8750\n",
      "Epoch 236/500\n",
      " - 0s - loss: 0.9819 - acc: 0.8750\n",
      "Epoch 237/500\n",
      " - 0s - loss: 0.9703 - acc: 0.8750\n",
      "Epoch 238/500\n",
      " - 0s - loss: 0.9588 - acc: 0.8750\n",
      "Epoch 239/500\n",
      " - 0s - loss: 0.9475 - acc: 0.8750\n",
      "Epoch 240/500\n",
      " - 0s - loss: 0.9363 - acc: 0.8750\n",
      "Epoch 241/500\n",
      " - 0s - loss: 0.9252 - acc: 0.8750\n",
      "Epoch 242/500\n",
      " - 0s - loss: 0.9142 - acc: 0.8750\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.9033 - acc: 0.8750\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.8926 - acc: 0.8750\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.8820 - acc: 0.8750\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.8715 - acc: 0.8750\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.8612 - acc: 0.8750\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.8509 - acc: 0.8750\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.8408 - acc: 0.8750\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.8308 - acc: 0.8750\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.8210 - acc: 0.8750\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.8112 - acc: 0.8750\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.8016 - acc: 0.8750\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.7921 - acc: 0.8750\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.7828 - acc: 0.8750\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.7736 - acc: 0.8750\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.7645 - acc: 0.8750\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.7555 - acc: 0.8750\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.7466 - acc: 0.8750\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.7379 - acc: 0.8750\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.7293 - acc: 0.8750\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.7208 - acc: 0.8750\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.7125 - acc: 0.8750\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.7042 - acc: 0.8750\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.6961 - acc: 0.8750\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.6881 - acc: 0.8750\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.6802 - acc: 0.8750\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.6725 - acc: 0.8750\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.6648 - acc: 0.8750\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.6573 - acc: 0.8750\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.6499 - acc: 0.8750\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.6426 - acc: 0.8750\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.6354 - acc: 0.8750\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.6284 - acc: 0.8750\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.6214 - acc: 0.8750\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.6146 - acc: 0.8750\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.6078 - acc: 0.8750\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.6012 - acc: 0.8750\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.5947 - acc: 0.8750\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.5882 - acc: 0.8750\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.5819 - acc: 0.8750\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.5757 - acc: 0.8750\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.5696 - acc: 0.8750\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.5636 - acc: 0.8750\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.5577 - acc: 0.8750\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.5519 - acc: 0.8750\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.5462 - acc: 0.8750\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.5405 - acc: 0.8750\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.5350 - acc: 0.8750\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.5296 - acc: 0.8750\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.5242 - acc: 0.8750\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.5190 - acc: 0.8750\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.5138 - acc: 0.8750\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.5088 - acc: 0.8750\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.5038 - acc: 0.8750\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.4989 - acc: 0.8750\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.4941 - acc: 0.8750\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.4893 - acc: 0.8750\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.4847 - acc: 0.8750\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.4801 - acc: 0.8750\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.4756 - acc: 0.8750\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.4712 - acc: 0.8750\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.4669 - acc: 0.8750\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.4626 - acc: 0.8750\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.4585 - acc: 0.8750\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.4544 - acc: 0.8750\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.4503 - acc: 0.8750\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.4464 - acc: 0.8750\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.4425 - acc: 0.8750\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.4387 - acc: 0.8750\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.4349 - acc: 0.8750\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.4312 - acc: 0.8750\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.4276 - acc: 0.8750\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.4240 - acc: 0.8750\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.4206 - acc: 0.8750\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.4171 - acc: 0.8750\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.4138 - acc: 0.8750\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.4105 - acc: 0.8750\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.4072 - acc: 0.8750\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.4040 - acc: 0.8750\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.4009 - acc: 0.8750\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.3978 - acc: 0.8750\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.3948 - acc: 0.8750\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.3918 - acc: 0.8750\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.3889 - acc: 0.8750\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.3861 - acc: 0.8750\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.3833 - acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/500\n",
      " - 0s - loss: 0.3805 - acc: 0.8750\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.3778 - acc: 0.8750\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.3751 - acc: 0.8750\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.3725 - acc: 0.8750\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.3700 - acc: 0.8750\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.3675 - acc: 0.8750\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.3650 - acc: 0.8750\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.3626 - acc: 0.8750\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.3602 - acc: 0.8750\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.3578 - acc: 0.8750\n",
      "Epoch 338/500\n",
      " - 0s - loss: 0.3556 - acc: 0.8750\n",
      "Epoch 339/500\n",
      " - 0s - loss: 0.3533 - acc: 0.8750\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.3511 - acc: 0.8750\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.3489 - acc: 0.8750\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.3468 - acc: 0.8750\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.3447 - acc: 0.8750\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.3426 - acc: 0.8750\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.3406 - acc: 0.8750\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.3386 - acc: 0.8750\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.3367 - acc: 0.8750\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.3348 - acc: 0.8750\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.3329 - acc: 0.8750\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.3310 - acc: 0.8750\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.3292 - acc: 0.8750\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.3274 - acc: 0.8750\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.3257 - acc: 0.8750\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.3240 - acc: 0.8750\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.3223 - acc: 0.8750\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.3206 - acc: 0.8750\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.3190 - acc: 0.8750\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.3174 - acc: 0.8750\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.3158 - acc: 0.8750\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.3143 - acc: 0.8750\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.3128 - acc: 0.8750\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.3113 - acc: 0.8750\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.3098 - acc: 0.8750\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.3084 - acc: 0.8750\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.3070 - acc: 0.8750\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.3056 - acc: 0.8750\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.3042 - acc: 0.8750\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.3029 - acc: 0.8750\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.3016 - acc: 0.8750\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.3003 - acc: 0.8750\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.2990 - acc: 0.8750\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.2978 - acc: 0.8750\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.2966 - acc: 0.8750\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.2954 - acc: 0.8750\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.2942 - acc: 0.8750\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.2930 - acc: 0.8750\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.2919 - acc: 0.8750\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.2908 - acc: 0.8750\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.2897 - acc: 0.8750\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.2886 - acc: 0.8750\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.2875 - acc: 0.8750\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.2865 - acc: 0.8750\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.2855 - acc: 0.8750\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.2844 - acc: 0.8750\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.2835 - acc: 0.8750\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.2825 - acc: 0.8750\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.2815 - acc: 0.8750\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.2806 - acc: 0.8750\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.2796 - acc: 0.8750\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.2787 - acc: 0.8750\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.2778 - acc: 0.8750\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.2769 - acc: 0.8750\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.2761 - acc: 0.8750\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.2752 - acc: 0.8750\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.2744 - acc: 0.8750\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.2735 - acc: 0.8750\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.2727 - acc: 0.8750\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.2719 - acc: 0.8750\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.2711 - acc: 0.8750\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.2703 - acc: 0.8750\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.2695 - acc: 0.8750\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.2688 - acc: 0.8750\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.2680 - acc: 0.8750\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.2673 - acc: 0.8750\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.2666 - acc: 0.8750\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.2659 - acc: 0.8750\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.2652 - acc: 0.8750\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.2645 - acc: 0.8750\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.2638 - acc: 0.8750\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.2631 - acc: 0.8750\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.2624 - acc: 0.8750\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.2618 - acc: 0.8750\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.2611 - acc: 0.8750\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.2605 - acc: 0.8750\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.2599 - acc: 0.8750\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.2593 - acc: 0.8750\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.2587 - acc: 0.8750\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.2581 - acc: 0.8750\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.2575 - acc: 0.8750\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.2569 - acc: 0.8750\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.2563 - acc: 0.8750\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.2557 - acc: 0.8750\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.2552 - acc: 0.8750\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.2546 - acc: 0.8750\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.2541 - acc: 0.8750\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.2535 - acc: 0.8750\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.2530 - acc: 0.8750\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.2525 - acc: 0.8750\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.2520 - acc: 0.8750\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.2515 - acc: 0.8750\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.2510 - acc: 0.8750\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.2505 - acc: 0.8750\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.2500 - acc: 0.8750\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.2495 - acc: 0.8750\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.2490 - acc: 0.8750\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.2486 - acc: 0.8750\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.2481 - acc: 0.8750\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.2476 - acc: 0.8750\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.2472 - acc: 0.8750\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.2467 - acc: 0.8750\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.2463 - acc: 0.8750\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.2459 - acc: 0.8750\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.2454 - acc: 0.8750\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.2450 - acc: 0.8750\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.2446 - acc: 0.8750\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.2442 - acc: 0.8750\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.2438 - acc: 0.8750\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.2434 - acc: 0.8750\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.2430 - acc: 0.8750\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.2426 - acc: 0.8750\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.2422 - acc: 0.8750\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.2418 - acc: 0.8750\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.2414 - acc: 0.8750\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.2411 - acc: 0.8750\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.2407 - acc: 0.8750\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.2403 - acc: 0.8750\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.2400 - acc: 0.8750\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.2396 - acc: 0.8750\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.2393 - acc: 0.8750\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.2389 - acc: 0.8750\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.2386 - acc: 0.8750\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.2382 - acc: 0.8750\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.2379 - acc: 0.8750\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.2376 - acc: 0.8750\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.2373 - acc: 0.8750\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.2369 - acc: 0.8750\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.2366 - acc: 0.8750\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.2363 - acc: 0.8750\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.2360 - acc: 0.8750\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.2357 - acc: 0.8750\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.2354 - acc: 0.8750\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.2351 - acc: 0.8750\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.2348 - acc: 0.8750\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.2345 - acc: 0.8750\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.2342 - acc: 0.8750\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.2339 - acc: 0.8750\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.2336 - acc: 0.8750\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.2333 - acc: 0.8750\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.2331 - acc: 0.8750\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.2328 - acc: 0.8750\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.2325 - acc: 0.8750\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.2323 - acc: 0.8750\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.2320 - acc: 0.8750\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.2317 - acc: 0.8750\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.2315 - acc: 0.8750\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.2312 - acc: 0.8750\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.2310 - acc: 0.8750\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.2307 - acc: 0.8750\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.2305 - acc: 0.8750\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.2302 - acc: 0.8750\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.2300 - acc: 0.8750\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.2297 - acc: 0.8750\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.2295 - acc: 0.8750\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.2293 - acc: 0.8750\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.2290 - acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500\n",
      " - 0s - loss: 0.2288 - acc: 0.8750\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.2286 - acc: 0.8750\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.2283 - acc: 0.8750\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.2281 - acc: 0.8750\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.2279 - acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x222067f7208>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QPP00G0iHJ3M",
    "outputId": "23dba855-d251-423d-d5a2-052df912b24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack and jill went up the hill\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "print(generate_seq(model, tokenizer, 'Jack', 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vV1nlZwsH2hc"
   },
   "source": [
    "# Model 2: Line-by-Line Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uOl_p5SxHTVL"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ht0NsnXTIBs2"
   },
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# pre-pad sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\t\t# predict probabilities for each word\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text += ' ' + out_word\n",
    "\treturn in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jA3dOwqzIEL9"
   },
   "outputs": [],
   "source": [
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "\t\tTo fetch a pail of water\\n\n",
    "\t\tJack fell down and broke his crown\\n\n",
    "\t\tAnd Jill came tumbling after\\n \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pF1qSkHwIGcK"
   },
   "outputs": [],
   "source": [
    "# prepare the tokenizer on the source text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E74yHEhBIJDF",
    "outputId": "ca56ff8e-869f-4f0d-b27d-efb0b02c6e50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 22\n"
     ]
    }
   ],
   "source": [
    "# determine the vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WZWFLOqpINGo",
    "outputId": "97b1894e-1256-4efd-c387-ed864d200518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 21\n"
     ]
    }
   ],
   "source": [
    "# create line-based sequences\n",
    "sequences = list()\n",
    "for line in data.split('\\n'):\n",
    "\tencoded = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(encoded)):\n",
    "\t\tsequence = encoded[:i+1]\n",
    "\t\tsequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "v-NCIrxTRTrl",
    "outputId": "8400f55f-b71c-48f2-8851-18807cc6efbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1],\n",
       " [2, 1, 3],\n",
       " [2, 1, 3, 4],\n",
       " [2, 1, 3, 4, 5],\n",
       " [2, 1, 3, 4, 5, 6],\n",
       " [2, 1, 3, 4, 5, 6, 7],\n",
       " [8, 9],\n",
       " [8, 9, 10],\n",
       " [8, 9, 10, 11],\n",
       " [8, 9, 10, 11, 12],\n",
       " [8, 9, 10, 11, 12, 13],\n",
       " [2, 14],\n",
       " [2, 14, 15],\n",
       " [2, 14, 15, 1],\n",
       " [2, 14, 15, 1, 16],\n",
       " [2, 14, 15, 1, 16, 17],\n",
       " [2, 14, 15, 1, 16, 17, 18],\n",
       " [1, 3],\n",
       " [1, 3, 19],\n",
       " [1, 3, 19, 20],\n",
       " [1, 3, 19, 20, 21]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ciPwhwAwIPyc",
    "outputId": "648882f0-1f29-4966-ad35-196d27c584bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 7\n"
     ]
    }
   ],
   "source": [
    "# pad input sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "poWiuHa_RcJO",
    "outputId": "cf09ea43-e530-44f2-b5e5-c6ed63251689"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  2,  1],\n",
       "       [ 0,  0,  0,  0,  2,  1,  3],\n",
       "       [ 0,  0,  0,  2,  1,  3,  4],\n",
       "       [ 0,  0,  2,  1,  3,  4,  5],\n",
       "       [ 0,  2,  1,  3,  4,  5,  6],\n",
       "       [ 2,  1,  3,  4,  5,  6,  7],\n",
       "       [ 0,  0,  0,  0,  0,  8,  9],\n",
       "       [ 0,  0,  0,  0,  8,  9, 10],\n",
       "       [ 0,  0,  0,  8,  9, 10, 11],\n",
       "       [ 0,  0,  8,  9, 10, 11, 12],\n",
       "       [ 0,  8,  9, 10, 11, 12, 13],\n",
       "       [ 0,  0,  0,  0,  0,  2, 14],\n",
       "       [ 0,  0,  0,  0,  2, 14, 15],\n",
       "       [ 0,  0,  0,  2, 14, 15,  1],\n",
       "       [ 0,  0,  2, 14, 15,  1, 16],\n",
       "       [ 0,  2, 14, 15,  1, 16, 17],\n",
       "       [ 2, 14, 15,  1, 16, 17, 18],\n",
       "       [ 0,  0,  0,  0,  0,  1,  3],\n",
       "       [ 0,  0,  0,  0,  1,  3, 19],\n",
       "       [ 0,  0,  0,  1,  3, 19, 20],\n",
       "       [ 0,  0,  1,  3, 19, 20, 21]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlMC-hjyISo7"
   },
   "outputs": [],
   "source": [
    "# split into input and output elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "N1wN-NgJRgwu",
    "outputId": "417d8033-6ff1-4884-8095-b43e78a31789"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  2,  1],\n",
       "       [ 0,  0,  0,  2,  1,  3],\n",
       "       [ 0,  0,  2,  1,  3,  4],\n",
       "       [ 0,  2,  1,  3,  4,  5],\n",
       "       [ 2,  1,  3,  4,  5,  6],\n",
       "       [ 0,  0,  0,  0,  0,  8],\n",
       "       [ 0,  0,  0,  0,  8,  9],\n",
       "       [ 0,  0,  0,  8,  9, 10],\n",
       "       [ 0,  0,  8,  9, 10, 11],\n",
       "       [ 0,  8,  9, 10, 11, 12],\n",
       "       [ 0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  2, 14],\n",
       "       [ 0,  0,  0,  2, 14, 15],\n",
       "       [ 0,  0,  2, 14, 15,  1],\n",
       "       [ 0,  2, 14, 15,  1, 16],\n",
       "       [ 2, 14, 15,  1, 16, 17],\n",
       "       [ 0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  1,  3],\n",
       "       [ 0,  0,  0,  1,  3, 19],\n",
       "       [ 0,  0,  1,  3, 19, 20]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "LAr21nDURhTv",
    "outputId": "16803d92-26cb-4146-d536-9b3d9409efc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "LSQ92wJ0IVQt",
    "outputId": "005a884f-7fb4-4689-a38d-b32649af64fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 6, 10)             220       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 22)                1122      \n",
      "=================================================================\n",
      "Total params: 13,542\n",
      "Trainable params: 13,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlZlKtxUIXZ2"
   },
   "outputs": [],
   "source": [
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AMLkMKtXIaIo",
    "outputId": "d732bbbb-cb29-43af-e73b-2c4e5ede8f58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 2s - loss: 3.0912 - acc: 0.0476\n",
      "Epoch 2/500\n",
      " - 0s - loss: 3.0895 - acc: 0.0952\n",
      "Epoch 3/500\n",
      " - 0s - loss: 3.0879 - acc: 0.1429\n",
      "Epoch 4/500\n",
      " - 0s - loss: 3.0863 - acc: 0.1905\n",
      "Epoch 5/500\n",
      " - 0s - loss: 3.0846 - acc: 0.1905\n",
      "Epoch 6/500\n",
      " - 0s - loss: 3.0829 - acc: 0.2381\n",
      "Epoch 7/500\n",
      " - 0s - loss: 3.0812 - acc: 0.1905\n",
      "Epoch 8/500\n",
      " - 0s - loss: 3.0794 - acc: 0.1429\n",
      "Epoch 9/500\n",
      " - 0s - loss: 3.0776 - acc: 0.0952\n",
      "Epoch 10/500\n",
      " - 0s - loss: 3.0757 - acc: 0.0952\n",
      "Epoch 11/500\n",
      " - 0s - loss: 3.0737 - acc: 0.0952\n",
      "Epoch 12/500\n",
      " - 0s - loss: 3.0716 - acc: 0.0952\n",
      "Epoch 13/500\n",
      " - 0s - loss: 3.0695 - acc: 0.0952\n",
      "Epoch 14/500\n",
      " - 0s - loss: 3.0672 - acc: 0.0952\n",
      "Epoch 15/500\n",
      " - 0s - loss: 3.0648 - acc: 0.0952\n",
      "Epoch 16/500\n",
      " - 0s - loss: 3.0623 - acc: 0.0952\n",
      "Epoch 17/500\n",
      " - 0s - loss: 3.0596 - acc: 0.0952\n",
      "Epoch 18/500\n",
      " - 0s - loss: 3.0568 - acc: 0.0952\n",
      "Epoch 19/500\n",
      " - 0s - loss: 3.0538 - acc: 0.0952\n",
      "Epoch 20/500\n",
      " - 0s - loss: 3.0505 - acc: 0.0952\n",
      "Epoch 21/500\n",
      " - 0s - loss: 3.0471 - acc: 0.0952\n",
      "Epoch 22/500\n",
      " - 0s - loss: 3.0434 - acc: 0.0952\n",
      "Epoch 23/500\n",
      " - 0s - loss: 3.0395 - acc: 0.0952\n",
      "Epoch 24/500\n",
      " - 0s - loss: 3.0353 - acc: 0.0952\n",
      "Epoch 25/500\n",
      " - 0s - loss: 3.0308 - acc: 0.0952\n",
      "Epoch 26/500\n",
      " - 0s - loss: 3.0260 - acc: 0.0952\n",
      "Epoch 27/500\n",
      " - 0s - loss: 3.0208 - acc: 0.0952\n",
      "Epoch 28/500\n",
      " - 0s - loss: 3.0152 - acc: 0.0952\n",
      "Epoch 29/500\n",
      " - 0s - loss: 3.0092 - acc: 0.0952\n",
      "Epoch 30/500\n",
      " - 0s - loss: 3.0027 - acc: 0.0952\n",
      "Epoch 31/500\n",
      " - 0s - loss: 2.9958 - acc: 0.0952\n",
      "Epoch 32/500\n",
      " - 0s - loss: 2.9883 - acc: 0.0952\n",
      "Epoch 33/500\n",
      " - 0s - loss: 2.9804 - acc: 0.0952\n",
      "Epoch 34/500\n",
      " - 0s - loss: 2.9718 - acc: 0.0952\n",
      "Epoch 35/500\n",
      " - 0s - loss: 2.9628 - acc: 0.0952\n",
      "Epoch 36/500\n",
      " - 0s - loss: 2.9532 - acc: 0.0952\n",
      "Epoch 37/500\n",
      " - 0s - loss: 2.9432 - acc: 0.0952\n",
      "Epoch 38/500\n",
      " - 0s - loss: 2.9327 - acc: 0.0952\n",
      "Epoch 39/500\n",
      " - 0s - loss: 2.9220 - acc: 0.0952\n",
      "Epoch 40/500\n",
      " - 0s - loss: 2.9113 - acc: 0.0952\n",
      "Epoch 41/500\n",
      " - 0s - loss: 2.9007 - acc: 0.0952\n",
      "Epoch 42/500\n",
      " - 0s - loss: 2.8906 - acc: 0.0952\n",
      "Epoch 43/500\n",
      " - 0s - loss: 2.8815 - acc: 0.0952\n",
      "Epoch 44/500\n",
      " - 0s - loss: 2.8733 - acc: 0.0952\n",
      "Epoch 45/500\n",
      " - 0s - loss: 2.8663 - acc: 0.0952\n",
      "Epoch 46/500\n",
      " - 0s - loss: 2.8598 - acc: 0.0952\n",
      "Epoch 47/500\n",
      " - 0s - loss: 2.8534 - acc: 0.0952\n",
      "Epoch 48/500\n",
      " - 0s - loss: 2.8462 - acc: 0.0952\n",
      "Epoch 49/500\n",
      " - 0s - loss: 2.8379 - acc: 0.0952\n",
      "Epoch 50/500\n",
      " - 0s - loss: 2.8282 - acc: 0.0952\n",
      "Epoch 51/500\n",
      " - 0s - loss: 2.8172 - acc: 0.0952\n",
      "Epoch 52/500\n",
      " - 0s - loss: 2.8055 - acc: 0.0952\n",
      "Epoch 53/500\n",
      " - 0s - loss: 2.7931 - acc: 0.0952\n",
      "Epoch 54/500\n",
      " - 0s - loss: 2.7805 - acc: 0.0952\n",
      "Epoch 55/500\n",
      " - 0s - loss: 2.7676 - acc: 0.0952\n",
      "Epoch 56/500\n",
      " - 0s - loss: 2.7545 - acc: 0.0952\n",
      "Epoch 57/500\n",
      " - 0s - loss: 2.7409 - acc: 0.1429\n",
      "Epoch 58/500\n",
      " - 0s - loss: 2.7269 - acc: 0.1429\n",
      "Epoch 59/500\n",
      " - 0s - loss: 2.7123 - acc: 0.1429\n",
      "Epoch 60/500\n",
      " - 0s - loss: 2.6967 - acc: 0.1429\n",
      "Epoch 61/500\n",
      " - 0s - loss: 2.6802 - acc: 0.1429\n",
      "Epoch 62/500\n",
      " - 0s - loss: 2.6626 - acc: 0.1429\n",
      "Epoch 63/500\n",
      " - 0s - loss: 2.6440 - acc: 0.1429\n",
      "Epoch 64/500\n",
      " - 0s - loss: 2.6244 - acc: 0.1905\n",
      "Epoch 65/500\n",
      " - 0s - loss: 2.6040 - acc: 0.2381\n",
      "Epoch 66/500\n",
      " - 0s - loss: 2.5827 - acc: 0.2381\n",
      "Epoch 67/500\n",
      " - 0s - loss: 2.5608 - acc: 0.2381\n",
      "Epoch 68/500\n",
      " - 0s - loss: 2.5381 - acc: 0.2381\n",
      "Epoch 69/500\n",
      " - 0s - loss: 2.5148 - acc: 0.2381\n",
      "Epoch 70/500\n",
      " - 0s - loss: 2.4905 - acc: 0.2381\n",
      "Epoch 71/500\n",
      " - 0s - loss: 2.4653 - acc: 0.2381\n",
      "Epoch 72/500\n",
      " - 0s - loss: 2.4390 - acc: 0.2381\n",
      "Epoch 73/500\n",
      " - 0s - loss: 2.4116 - acc: 0.2381\n",
      "Epoch 74/500\n",
      " - 0s - loss: 2.3834 - acc: 0.2381\n",
      "Epoch 75/500\n",
      " - 0s - loss: 2.3543 - acc: 0.2381\n",
      "Epoch 76/500\n",
      " - 0s - loss: 2.3245 - acc: 0.2381\n",
      "Epoch 77/500\n",
      " - 0s - loss: 2.2936 - acc: 0.2381\n",
      "Epoch 78/500\n",
      " - 0s - loss: 2.2618 - acc: 0.2857\n",
      "Epoch 79/500\n",
      " - 0s - loss: 2.2283 - acc: 0.3333\n",
      "Epoch 80/500\n",
      " - 0s - loss: 2.1934 - acc: 0.3333\n",
      "Epoch 81/500\n",
      " - 0s - loss: 2.1584 - acc: 0.3333\n",
      "Epoch 82/500\n",
      " - 0s - loss: 2.1240 - acc: 0.3333\n",
      "Epoch 83/500\n",
      " - 0s - loss: 2.0894 - acc: 0.3333\n",
      "Epoch 84/500\n",
      " - 0s - loss: 2.0559 - acc: 0.4286\n",
      "Epoch 85/500\n",
      " - 0s - loss: 2.0221 - acc: 0.4286\n",
      "Epoch 86/500\n",
      " - 0s - loss: 1.9876 - acc: 0.4286\n",
      "Epoch 87/500\n",
      " - 0s - loss: 1.9526 - acc: 0.4286\n",
      "Epoch 88/500\n",
      " - 0s - loss: 1.9165 - acc: 0.4762\n",
      "Epoch 89/500\n",
      " - 0s - loss: 1.8804 - acc: 0.5238\n",
      "Epoch 90/500\n",
      " - 0s - loss: 1.8446 - acc: 0.5238\n",
      "Epoch 91/500\n",
      " - 0s - loss: 1.8089 - acc: 0.5238\n",
      "Epoch 92/500\n",
      " - 0s - loss: 1.7733 - acc: 0.5238\n",
      "Epoch 93/500\n",
      " - 0s - loss: 1.7382 - acc: 0.5238\n",
      "Epoch 94/500\n",
      " - 0s - loss: 1.7038 - acc: 0.5714\n",
      "Epoch 95/500\n",
      " - 0s - loss: 1.6705 - acc: 0.6190\n",
      "Epoch 96/500\n",
      " - 0s - loss: 1.6390 - acc: 0.6667\n",
      "Epoch 97/500\n",
      " - 0s - loss: 1.6086 - acc: 0.6667\n",
      "Epoch 98/500\n",
      " - 0s - loss: 1.5791 - acc: 0.7143\n",
      "Epoch 99/500\n",
      " - 0s - loss: 1.5513 - acc: 0.7143\n",
      "Epoch 100/500\n",
      " - 0s - loss: 1.5242 - acc: 0.7619\n",
      "Epoch 101/500\n",
      " - 0s - loss: 1.4983 - acc: 0.7619\n",
      "Epoch 102/500\n",
      " - 0s - loss: 1.4736 - acc: 0.7619\n",
      "Epoch 103/500\n",
      " - 0s - loss: 1.4496 - acc: 0.7619\n",
      "Epoch 104/500\n",
      " - 0s - loss: 1.4266 - acc: 0.7143\n",
      "Epoch 105/500\n",
      " - 0s - loss: 1.4047 - acc: 0.7143\n",
      "Epoch 106/500\n",
      " - 0s - loss: 1.3836 - acc: 0.7143\n",
      "Epoch 107/500\n",
      " - 0s - loss: 1.3628 - acc: 0.7143\n",
      "Epoch 108/500\n",
      " - 0s - loss: 1.3427 - acc: 0.7143\n",
      "Epoch 109/500\n",
      " - 0s - loss: 1.3230 - acc: 0.7143\n",
      "Epoch 110/500\n",
      " - 0s - loss: 1.3044 - acc: 0.7143\n",
      "Epoch 111/500\n",
      " - 0s - loss: 1.2863 - acc: 0.7143\n",
      "Epoch 112/500\n",
      " - 0s - loss: 1.2687 - acc: 0.7143\n",
      "Epoch 113/500\n",
      " - 0s - loss: 1.2515 - acc: 0.7143\n",
      "Epoch 114/500\n",
      " - 0s - loss: 1.2343 - acc: 0.7619\n",
      "Epoch 115/500\n",
      " - 0s - loss: 1.2175 - acc: 0.7619\n",
      "Epoch 116/500\n",
      " - 0s - loss: 1.2008 - acc: 0.7619\n",
      "Epoch 117/500\n",
      " - 0s - loss: 1.1843 - acc: 0.7619\n",
      "Epoch 118/500\n",
      " - 0s - loss: 1.1682 - acc: 0.7619\n",
      "Epoch 119/500\n",
      " - 0s - loss: 1.1524 - acc: 0.7619\n",
      "Epoch 120/500\n",
      " - 0s - loss: 1.1370 - acc: 0.7619\n",
      "Epoch 121/500\n",
      " - 0s - loss: 1.1220 - acc: 0.7619\n",
      "Epoch 122/500\n",
      " - 0s - loss: 1.1071 - acc: 0.7619\n",
      "Epoch 123/500\n",
      " - 0s - loss: 1.0924 - acc: 0.7619\n",
      "Epoch 124/500\n",
      " - 0s - loss: 1.0778 - acc: 0.7619\n",
      "Epoch 125/500\n",
      " - 0s - loss: 1.0634 - acc: 0.7619\n",
      "Epoch 126/500\n",
      " - 0s - loss: 1.0489 - acc: 0.7619\n",
      "Epoch 127/500\n",
      " - 0s - loss: 1.0347 - acc: 0.7619\n",
      "Epoch 128/500\n",
      " - 0s - loss: 1.0205 - acc: 0.7619\n",
      "Epoch 129/500\n",
      " - 0s - loss: 1.0065 - acc: 0.7619\n",
      "Epoch 130/500\n",
      " - 0s - loss: 0.9927 - acc: 0.7619\n",
      "Epoch 131/500\n",
      " - 0s - loss: 0.9793 - acc: 0.7619\n",
      "Epoch 132/500\n",
      " - 0s - loss: 0.9663 - acc: 0.7619\n",
      "Epoch 133/500\n",
      " - 0s - loss: 0.9538 - acc: 0.7619\n",
      "Epoch 134/500\n",
      " - 0s - loss: 0.9416 - acc: 0.7619\n",
      "Epoch 135/500\n",
      " - 0s - loss: 0.9296 - acc: 0.7619\n",
      "Epoch 136/500\n",
      " - 0s - loss: 0.9180 - acc: 0.7619\n",
      "Epoch 137/500\n",
      " - 0s - loss: 0.9068 - acc: 0.7619\n",
      "Epoch 138/500\n",
      " - 0s - loss: 0.8959 - acc: 0.7619\n",
      "Epoch 139/500\n",
      " - 0s - loss: 0.8854 - acc: 0.7619\n",
      "Epoch 140/500\n",
      " - 0s - loss: 0.8752 - acc: 0.7619\n",
      "Epoch 141/500\n",
      " - 0s - loss: 0.8652 - acc: 0.7619\n",
      "Epoch 142/500\n",
      " - 0s - loss: 0.8556 - acc: 0.8095\n",
      "Epoch 143/500\n",
      " - 0s - loss: 0.8462 - acc: 0.8095\n",
      "Epoch 144/500\n",
      " - 0s - loss: 0.8372 - acc: 0.8095\n",
      "Epoch 145/500\n",
      " - 0s - loss: 0.8284 - acc: 0.8095\n",
      "Epoch 146/500\n",
      " - 0s - loss: 0.8198 - acc: 0.8095\n",
      "Epoch 147/500\n",
      " - 0s - loss: 0.8115 - acc: 0.8571\n",
      "Epoch 148/500\n",
      " - 0s - loss: 0.8033 - acc: 0.8571\n",
      "Epoch 149/500\n",
      " - 0s - loss: 0.7953 - acc: 0.8571\n",
      "Epoch 150/500\n",
      " - 0s - loss: 0.7875 - acc: 0.8571\n",
      "Epoch 151/500\n",
      " - 0s - loss: 0.7799 - acc: 0.8571\n",
      "Epoch 152/500\n",
      " - 0s - loss: 0.7725 - acc: 0.8571\n",
      "Epoch 153/500\n",
      " - 0s - loss: 0.7652 - acc: 0.8571\n",
      "Epoch 154/500\n",
      " - 0s - loss: 0.7581 - acc: 0.8571\n",
      "Epoch 155/500\n",
      " - 0s - loss: 0.7512 - acc: 0.8571\n",
      "Epoch 156/500\n",
      " - 0s - loss: 0.7444 - acc: 0.8571\n",
      "Epoch 157/500\n",
      " - 0s - loss: 0.7377 - acc: 0.8571\n",
      "Epoch 158/500\n",
      " - 0s - loss: 0.7311 - acc: 0.8571\n",
      "Epoch 159/500\n",
      " - 0s - loss: 0.7246 - acc: 0.8571\n",
      "Epoch 160/500\n",
      " - 0s - loss: 0.7181 - acc: 0.8571\n",
      "Epoch 161/500\n",
      " - 0s - loss: 0.7117 - acc: 0.8571\n",
      "Epoch 162/500\n",
      " - 0s - loss: 0.7054 - acc: 0.8571\n",
      "Epoch 163/500\n",
      " - 0s - loss: 0.6990 - acc: 0.8571\n",
      "Epoch 164/500\n",
      " - 0s - loss: 0.6928 - acc: 0.8571\n",
      "Epoch 165/500\n",
      " - 0s - loss: 0.6869 - acc: 0.8571\n",
      "Epoch 166/500\n",
      " - 0s - loss: 0.6811 - acc: 0.8571\n",
      "Epoch 167/500\n",
      " - 0s - loss: 0.6753 - acc: 0.8571\n",
      "Epoch 168/500\n",
      " - 0s - loss: 0.6699 - acc: 0.8571\n",
      "Epoch 169/500\n",
      " - 0s - loss: 0.6647 - acc: 0.8571\n",
      "Epoch 170/500\n",
      " - 0s - loss: 0.6594 - acc: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/500\n",
      " - 0s - loss: 0.6542 - acc: 0.8571\n",
      "Epoch 172/500\n",
      " - 0s - loss: 0.6489 - acc: 0.8571\n",
      "Epoch 173/500\n",
      " - 0s - loss: 0.6439 - acc: 0.8571\n",
      "Epoch 174/500\n",
      " - 0s - loss: 0.6391 - acc: 0.8571\n",
      "Epoch 175/500\n",
      " - 0s - loss: 0.6344 - acc: 0.8571\n",
      "Epoch 176/500\n",
      " - 0s - loss: 0.6296 - acc: 0.8571\n",
      "Epoch 177/500\n",
      " - 0s - loss: 0.6248 - acc: 0.8571\n",
      "Epoch 178/500\n",
      " - 0s - loss: 0.6202 - acc: 0.8571\n",
      "Epoch 179/500\n",
      " - 0s - loss: 0.6157 - acc: 0.8571\n",
      "Epoch 180/500\n",
      " - 0s - loss: 0.6112 - acc: 0.8571\n",
      "Epoch 181/500\n",
      " - 0s - loss: 0.6068 - acc: 0.8571\n",
      "Epoch 182/500\n",
      " - 0s - loss: 0.6024 - acc: 0.8571\n",
      "Epoch 183/500\n",
      " - 0s - loss: 0.5982 - acc: 0.8571\n",
      "Epoch 184/500\n",
      " - 0s - loss: 0.5940 - acc: 0.8571\n",
      "Epoch 185/500\n",
      " - 0s - loss: 0.5898 - acc: 0.8571\n",
      "Epoch 186/500\n",
      " - 0s - loss: 0.5858 - acc: 0.8571\n",
      "Epoch 187/500\n",
      " - 0s - loss: 0.5817 - acc: 0.8571\n",
      "Epoch 188/500\n",
      " - 0s - loss: 0.5778 - acc: 0.8571\n",
      "Epoch 189/500\n",
      " - 0s - loss: 0.5738 - acc: 0.8571\n",
      "Epoch 190/500\n",
      " - 0s - loss: 0.5700 - acc: 0.8571\n",
      "Epoch 191/500\n",
      " - 0s - loss: 0.5662 - acc: 0.8571\n",
      "Epoch 192/500\n",
      " - 0s - loss: 0.5625 - acc: 0.8571\n",
      "Epoch 193/500\n",
      " - 0s - loss: 0.5587 - acc: 0.8571\n",
      "Epoch 194/500\n",
      " - 0s - loss: 0.5549 - acc: 0.8571\n",
      "Epoch 195/500\n",
      " - 0s - loss: 0.5513 - acc: 0.8571\n",
      "Epoch 196/500\n",
      " - 0s - loss: 0.5477 - acc: 0.8571\n",
      "Epoch 197/500\n",
      " - 0s - loss: 0.5442 - acc: 0.8571\n",
      "Epoch 198/500\n",
      " - 0s - loss: 0.5409 - acc: 0.8571\n",
      "Epoch 199/500\n",
      " - 0s - loss: 0.5374 - acc: 0.8571\n",
      "Epoch 200/500\n",
      " - 0s - loss: 0.5339 - acc: 0.8571\n",
      "Epoch 201/500\n",
      " - 0s - loss: 0.5302 - acc: 0.8571\n",
      "Epoch 202/500\n",
      " - 0s - loss: 0.5268 - acc: 0.8571\n",
      "Epoch 203/500\n",
      " - 0s - loss: 0.5234 - acc: 0.8571\n",
      "Epoch 204/500\n",
      " - 0s - loss: 0.5203 - acc: 0.8571\n",
      "Epoch 205/500\n",
      " - 0s - loss: 0.5169 - acc: 0.8571\n",
      "Epoch 206/500\n",
      " - 0s - loss: 0.5135 - acc: 0.8571\n",
      "Epoch 207/500\n",
      " - 0s - loss: 0.5101 - acc: 0.8571\n",
      "Epoch 208/500\n",
      " - 0s - loss: 0.5069 - acc: 0.8571\n",
      "Epoch 209/500\n",
      " - 0s - loss: 0.5037 - acc: 0.8571\n",
      "Epoch 210/500\n",
      " - 0s - loss: 0.5004 - acc: 0.8571\n",
      "Epoch 211/500\n",
      " - 0s - loss: 0.4971 - acc: 0.8571\n",
      "Epoch 212/500\n",
      " - 0s - loss: 0.4941 - acc: 0.8571\n",
      "Epoch 213/500\n",
      " - 0s - loss: 0.4911 - acc: 0.8571\n",
      "Epoch 214/500\n",
      " - 0s - loss: 0.4880 - acc: 0.8571\n",
      "Epoch 215/500\n",
      " - 0s - loss: 0.4846 - acc: 0.8571\n",
      "Epoch 216/500\n",
      " - 0s - loss: 0.4815 - acc: 0.8571\n",
      "Epoch 217/500\n",
      " - 0s - loss: 0.4787 - acc: 0.8571\n",
      "Epoch 218/500\n",
      " - 0s - loss: 0.4756 - acc: 0.9048\n",
      "Epoch 219/500\n",
      " - 0s - loss: 0.4723 - acc: 0.9048\n",
      "Epoch 220/500\n",
      " - 0s - loss: 0.4695 - acc: 0.9048\n",
      "Epoch 221/500\n",
      " - 0s - loss: 0.4666 - acc: 0.9048\n",
      "Epoch 222/500\n",
      " - 0s - loss: 0.4636 - acc: 0.9048\n",
      "Epoch 223/500\n",
      " - 0s - loss: 0.4605 - acc: 0.9048\n",
      "Epoch 224/500\n",
      " - 0s - loss: 0.4577 - acc: 0.9048\n",
      "Epoch 225/500\n",
      " - 0s - loss: 0.4548 - acc: 0.9048\n",
      "Epoch 226/500\n",
      " - 0s - loss: 0.4520 - acc: 0.9048\n",
      "Epoch 227/500\n",
      " - 0s - loss: 0.4490 - acc: 0.9048\n",
      "Epoch 228/500\n",
      " - 0s - loss: 0.4464 - acc: 0.9048\n",
      "Epoch 229/500\n",
      " - 0s - loss: 0.4437 - acc: 0.9048\n",
      "Epoch 230/500\n",
      " - 0s - loss: 0.4409 - acc: 0.9048\n",
      "Epoch 231/500\n",
      " - 0s - loss: 0.4379 - acc: 0.9048\n",
      "Epoch 232/500\n",
      " - 0s - loss: 0.4355 - acc: 0.9048\n",
      "Epoch 233/500\n",
      " - 0s - loss: 0.4327 - acc: 0.9048\n",
      "Epoch 234/500\n",
      " - 0s - loss: 0.4299 - acc: 0.9048\n",
      "Epoch 235/500\n",
      " - 0s - loss: 0.4271 - acc: 0.9048\n",
      "Epoch 236/500\n",
      " - 0s - loss: 0.4247 - acc: 0.9048\n",
      "Epoch 237/500\n",
      " - 0s - loss: 0.4219 - acc: 0.9048\n",
      "Epoch 238/500\n",
      " - 0s - loss: 0.4192 - acc: 0.9048\n",
      "Epoch 239/500\n",
      " - 0s - loss: 0.4168 - acc: 0.9048\n",
      "Epoch 240/500\n",
      " - 0s - loss: 0.4140 - acc: 0.9048\n",
      "Epoch 241/500\n",
      " - 0s - loss: 0.4116 - acc: 0.9048\n",
      "Epoch 242/500\n",
      " - 0s - loss: 0.4089 - acc: 0.9048\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.4066 - acc: 0.9048\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.4039 - acc: 0.9048\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.4016 - acc: 0.9048\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.3989 - acc: 0.9048\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.3966 - acc: 0.9048\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.3940 - acc: 0.9048\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.3916 - acc: 0.9048\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.3893 - acc: 0.9048\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.3869 - acc: 0.9048\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.3844 - acc: 0.9048\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.3820 - acc: 0.9048\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.3798 - acc: 0.9048\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.3773 - acc: 0.9048\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.3750 - acc: 0.9048\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.3728 - acc: 0.9048\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.3703 - acc: 0.9048\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.3681 - acc: 0.9048\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.3659 - acc: 0.9048\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.3635 - acc: 0.9048\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.3612 - acc: 0.9048\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.3593 - acc: 0.9048\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.3569 - acc: 0.9048\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.3546 - acc: 0.9048\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.3523 - acc: 0.9048\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.3503 - acc: 0.9048\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.3480 - acc: 0.9048\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.3459 - acc: 0.9048\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.3437 - acc: 0.9048\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.3415 - acc: 0.9048\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.3394 - acc: 0.9524\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.3372 - acc: 0.9524\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.3352 - acc: 0.9524\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.3330 - acc: 0.9524\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.3310 - acc: 0.9524\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.3290 - acc: 0.9524\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.3269 - acc: 0.9524\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.3248 - acc: 0.9524\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.3229 - acc: 0.9524\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.3208 - acc: 0.9524\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.3187 - acc: 0.9524\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.3167 - acc: 0.9524\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.3148 - acc: 0.9524\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.3127 - acc: 0.9524\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.3108 - acc: 0.9524\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.3088 - acc: 0.9524\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.3068 - acc: 0.9524\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.3051 - acc: 0.9524\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.3031 - acc: 0.9524\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.3010 - acc: 0.9524\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.2993 - acc: 0.9524\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.2974 - acc: 0.9524\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.2954 - acc: 0.9524\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.2936 - acc: 0.9524\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.2917 - acc: 0.9524\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.2898 - acc: 0.9524\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.2880 - acc: 0.9524\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.2861 - acc: 0.9524\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.2843 - acc: 0.9524\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.2825 - acc: 0.9524\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.2806 - acc: 0.9524\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.2788 - acc: 0.9524\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.2771 - acc: 0.9524\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.2752 - acc: 0.9524\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.2736 - acc: 0.9524\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.2719 - acc: 0.9524\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.2701 - acc: 0.9524\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.2683 - acc: 0.9524\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.2668 - acc: 0.9524\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.2650 - acc: 0.9524\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.2633 - acc: 0.9524\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.2617 - acc: 0.9524\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.2598 - acc: 0.9524\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.2584 - acc: 0.9524\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.2566 - acc: 0.9524\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.2549 - acc: 0.9524\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.2534 - acc: 0.9524\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.2516 - acc: 0.9524\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.2502 - acc: 0.9524\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.2486 - acc: 0.9524\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.2469 - acc: 0.9524\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.2454 - acc: 0.9524\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.2437 - acc: 0.9524\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.2422 - acc: 0.9524\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.2406 - acc: 0.9524\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.2391 - acc: 0.9524\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.2377 - acc: 0.9524\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.2360 - acc: 0.9524\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.2347 - acc: 0.9524\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.2331 - acc: 0.9524\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.2315 - acc: 0.9524\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.2303 - acc: 0.9524\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.2286 - acc: 0.9524\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.2273 - acc: 0.9524\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.2257 - acc: 0.9524\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.2244 - acc: 0.9524\n",
      "Epoch 338/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2229 - acc: 0.9524\n",
      "Epoch 339/500\n",
      " - 0s - loss: 0.2216 - acc: 0.9524\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.2201 - acc: 0.9524\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.2188 - acc: 0.9524\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.2174 - acc: 0.9524\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.2160 - acc: 0.9524\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.2147 - acc: 0.9524\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.2133 - acc: 0.9524\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.2120 - acc: 0.9524\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.2109 - acc: 0.9524\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.2095 - acc: 0.9524\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.2082 - acc: 0.9524\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.2070 - acc: 0.9524\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.2057 - acc: 0.9524\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.2046 - acc: 0.9524\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.2032 - acc: 0.9524\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.2021 - acc: 0.9524\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.2009 - acc: 0.9524\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.1997 - acc: 0.9524\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.1985 - acc: 0.9524\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.1973 - acc: 0.9524\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.1962 - acc: 0.9524\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.1950 - acc: 0.9524\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.1939 - acc: 0.9524\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.1928 - acc: 0.9524\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.1917 - acc: 0.9524\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.1906 - acc: 0.9524\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.1895 - acc: 0.9524\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.1884 - acc: 0.9524\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.1874 - acc: 0.9524\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.1863 - acc: 0.9524\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.1852 - acc: 0.9524\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.1842 - acc: 0.9524\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.1832 - acc: 0.9524\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.1822 - acc: 0.9524\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.1812 - acc: 0.9524\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.1802 - acc: 0.9524\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.1792 - acc: 0.9524\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.1782 - acc: 0.9524\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.1773 - acc: 0.9524\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.1763 - acc: 0.9524\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.1754 - acc: 0.9524\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.1746 - acc: 0.9524\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.1735 - acc: 0.9524\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.1728 - acc: 0.9524\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.1717 - acc: 0.9524\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.1710 - acc: 0.9524\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.1700 - acc: 0.9524\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.1693 - acc: 0.9524\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.1683 - acc: 0.9524\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.1675 - acc: 0.9524\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.1666 - acc: 0.9524\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.1657 - acc: 0.9524\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.1649 - acc: 0.9524\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.1640 - acc: 0.9524\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.1632 - acc: 0.9524\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.1624 - acc: 0.9524\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.1616 - acc: 0.9524\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.1609 - acc: 0.9524\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.1601 - acc: 0.9524\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.1593 - acc: 0.9524\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.1585 - acc: 0.9524\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.1578 - acc: 0.9524\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.1571 - acc: 0.9524\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.1563 - acc: 0.9524\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.1556 - acc: 0.9524\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.1548 - acc: 0.9524\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.1541 - acc: 0.9524\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.1534 - acc: 0.9524\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.1527 - acc: 0.9524\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.1520 - acc: 0.9524\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.1513 - acc: 0.9524\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.1506 - acc: 0.9524\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.1500 - acc: 0.9524\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.1493 - acc: 0.9524\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.1486 - acc: 0.9524\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.1480 - acc: 0.9524\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.1473 - acc: 0.9524\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.1467 - acc: 0.9524\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.1460 - acc: 0.9524\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.1454 - acc: 0.9524\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.1448 - acc: 0.9524\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.1442 - acc: 0.9524\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.1436 - acc: 0.9524\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.1430 - acc: 0.9524\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.1424 - acc: 0.9524\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.1418 - acc: 0.9524\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.1413 - acc: 0.9524\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.1406 - acc: 0.9524\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.1401 - acc: 0.9524\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.1395 - acc: 0.9524\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.1389 - acc: 0.9524\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.1384 - acc: 0.9524\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.1378 - acc: 0.9524\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.1373 - acc: 0.9524\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.1367 - acc: 0.9524\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.1363 - acc: 0.9524\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.1357 - acc: 0.9524\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.1352 - acc: 0.9524\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.1347 - acc: 0.9524\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.1342 - acc: 0.9524\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.1337 - acc: 0.9524\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.1332 - acc: 0.9524\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.1327 - acc: 0.9524\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.1323 - acc: 0.9524\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.1317 - acc: 0.9524\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.1312 - acc: 0.9524\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.1308 - acc: 0.9524\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.1303 - acc: 0.9524\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.1299 - acc: 0.9524\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.1294 - acc: 0.9524\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.1290 - acc: 0.9524\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.1285 - acc: 0.9524\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.1281 - acc: 0.9524\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.1276 - acc: 0.9524\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.1273 - acc: 0.9524\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.1267 - acc: 0.9524\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.1263 - acc: 0.9524\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.1259 - acc: 0.9524\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.1255 - acc: 0.9524\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.1250 - acc: 0.9524\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.1247 - acc: 0.9524\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.1242 - acc: 0.9524\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.1238 - acc: 0.9524\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.1234 - acc: 0.9524\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.1230 - acc: 0.9524\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.1226 - acc: 0.9524\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.1222 - acc: 0.9524\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.1219 - acc: 0.9524\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.1215 - acc: 0.9524\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.1211 - acc: 0.9524\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.1207 - acc: 0.9524\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.1203 - acc: 0.9524\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.1199 - acc: 0.9524\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.1196 - acc: 0.9524\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.1192 - acc: 0.9524\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.1189 - acc: 0.9524\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.1186 - acc: 0.9524\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.1182 - acc: 0.9524\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.1178 - acc: 0.9524\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.1175 - acc: 0.9524\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.1171 - acc: 0.9524\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.1168 - acc: 0.9524\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.1165 - acc: 0.9524\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.1161 - acc: 0.9524\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.1158 - acc: 0.9524\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.1155 - acc: 0.9524\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.1152 - acc: 0.9524\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.1148 - acc: 0.9524\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.1145 - acc: 0.9524\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.1142 - acc: 0.9524\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.1139 - acc: 0.9524\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.1135 - acc: 0.9524\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.1132 - acc: 0.9524\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.1129 - acc: 0.9524\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.1126 - acc: 0.9524\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.1123 - acc: 0.9524\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.1121 - acc: 0.9524\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.1117 - acc: 0.9524\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.1114 - acc: 0.9524\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.1112 - acc: 0.9524\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.1108 - acc: 0.9524\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.1106 - acc: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2220a7037c8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VO__NG7hIdwJ",
    "outputId": "4daed1fb-1222-4dea-d3a6-60ddf398fea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack fell down and broke\n",
      "Jill jill came tumbling after\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jack', 4))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jill', 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_quUTNmIoG9"
   },
   "source": [
    "# Model 3: Two-Words-In, One-Word-Out Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1Uw91yRIhj4"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZ_4iC82Irxh"
   },
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# pre-pad sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\t\t# predict probabilities for each word\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text += ' ' + out_word\n",
    "\treturn in_text\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Afe1TmVBIuAH"
   },
   "outputs": [],
   "source": [
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "\t\tTo fetch a pail of water\\n\n",
    "\t\tJack fell down and broke his crown\\n\n",
    "\t\tAnd Jill came tumbling after\\n \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BuOBeVJmIwVA"
   },
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "RAuVDk-ZRyF9",
    "outputId": "ebe18dbc-2448-4774-e587-a2200bdeac51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 2,\n",
       " 14,\n",
       " 15,\n",
       " 1,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 1,\n",
       " 3,\n",
       " 19,\n",
       " 20,\n",
       " 21]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NwXuP3GqIydC",
    "outputId": "de925a07-c7d5-40e6-a15c-170e114828dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 22\n"
     ]
    }
   ],
   "source": [
    "# retrieve vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ESiCbLmsI00K",
    "outputId": "d9ea748b-c3bd-45fa-b2a0-d185b7ef3d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 23\n"
     ]
    }
   ],
   "source": [
    "# encode 2 words -> 1 word\n",
    "sequences = list()\n",
    "for i in range(2, len(encoded)):\n",
    "\tsequence = encoded[i-2:i+1]\n",
    "\tsequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "pjycQeGCR2rR",
    "outputId": "7ba8e16e-3732-4693-d747-d7001135c831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 3],\n",
       " [1, 3, 4],\n",
       " [3, 4, 5],\n",
       " [4, 5, 6],\n",
       " [5, 6, 7],\n",
       " [6, 7, 8],\n",
       " [7, 8, 9],\n",
       " [8, 9, 10],\n",
       " [9, 10, 11],\n",
       " [10, 11, 12],\n",
       " [11, 12, 13],\n",
       " [12, 13, 2],\n",
       " [13, 2, 14],\n",
       " [2, 14, 15],\n",
       " [14, 15, 1],\n",
       " [15, 1, 16],\n",
       " [1, 16, 17],\n",
       " [16, 17, 18],\n",
       " [17, 18, 1],\n",
       " [18, 1, 3],\n",
       " [1, 3, 19],\n",
       " [3, 19, 20],\n",
       " [19, 20, 21]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o2Ue8MoHI3nN",
    "outputId": "fe16f887-74a4-434f-ea1b-afac96456610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 3\n"
     ]
    }
   ],
   "source": [
    "# pad sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "pr30b5pvR9Pi",
    "outputId": "b2f049cf-ef7d-4f95-e357-3da86f465b2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  1,  3],\n",
       "       [ 1,  3,  4],\n",
       "       [ 3,  4,  5],\n",
       "       [ 4,  5,  6],\n",
       "       [ 5,  6,  7],\n",
       "       [ 6,  7,  8],\n",
       "       [ 7,  8,  9],\n",
       "       [ 8,  9, 10],\n",
       "       [ 9, 10, 11],\n",
       "       [10, 11, 12],\n",
       "       [11, 12, 13],\n",
       "       [12, 13,  2],\n",
       "       [13,  2, 14],\n",
       "       [ 2, 14, 15],\n",
       "       [14, 15,  1],\n",
       "       [15,  1, 16],\n",
       "       [ 1, 16, 17],\n",
       "       [16, 17, 18],\n",
       "       [17, 18,  1],\n",
       "       [18,  1,  3],\n",
       "       [ 1,  3, 19],\n",
       "       [ 3, 19, 20],\n",
       "       [19, 20, 21]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAE6ZRZAI5wp"
   },
   "outputs": [],
   "source": [
    "# split into input and output elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "UobxG-SxSAVK",
    "outputId": "d094f55b-30a6-4ebf-e87c-29972eaff561"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  1],\n",
       "       [ 1,  3],\n",
       "       [ 3,  4],\n",
       "       [ 4,  5],\n",
       "       [ 5,  6],\n",
       "       [ 6,  7],\n",
       "       [ 7,  8],\n",
       "       [ 8,  9],\n",
       "       [ 9, 10],\n",
       "       [10, 11],\n",
       "       [11, 12],\n",
       "       [12, 13],\n",
       "       [13,  2],\n",
       "       [ 2, 14],\n",
       "       [14, 15],\n",
       "       [15,  1],\n",
       "       [ 1, 16],\n",
       "       [16, 17],\n",
       "       [17, 18],\n",
       "       [18,  1],\n",
       "       [ 1,  3],\n",
       "       [ 3, 19],\n",
       "       [19, 20]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "cD19MggOSAuu",
    "outputId": "e3e1d73b-a3c2-4984-8ac6-c8f52087fb67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "am-6WyyXI8fn",
    "outputId": "d169dd58-2c78-4c45-c859-9e870c97ea38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2, 10)             220       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 22)                1122      \n",
      "=================================================================\n",
      "Total params: 13,542\n",
      "Trainable params: 13,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtRY1MpvI-y-"
   },
   "outputs": [],
   "source": [
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Bvhs8SRYJBkE",
    "outputId": "f0e48f5c-eded-4778-c423-d8532dd947b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 2s - loss: 3.0912 - acc: 0.0435\n",
      "Epoch 2/500\n",
      " - 0s - loss: 3.0904 - acc: 0.0435\n",
      "Epoch 3/500\n",
      " - 0s - loss: 3.0895 - acc: 0.1304\n",
      "Epoch 4/500\n",
      " - 0s - loss: 3.0887 - acc: 0.1304\n",
      "Epoch 5/500\n",
      " - 0s - loss: 3.0878 - acc: 0.1304\n",
      "Epoch 6/500\n",
      " - 0s - loss: 3.0870 - acc: 0.1304\n",
      "Epoch 7/500\n",
      " - 0s - loss: 3.0861 - acc: 0.1304\n",
      "Epoch 8/500\n",
      " - 0s - loss: 3.0852 - acc: 0.1304\n",
      "Epoch 9/500\n",
      " - 0s - loss: 3.0844 - acc: 0.1304\n",
      "Epoch 10/500\n",
      " - 0s - loss: 3.0835 - acc: 0.1304\n",
      "Epoch 11/500\n",
      " - 0s - loss: 3.0825 - acc: 0.1739\n",
      "Epoch 12/500\n",
      " - 0s - loss: 3.0816 - acc: 0.1739\n",
      "Epoch 13/500\n",
      " - 0s - loss: 3.0807 - acc: 0.1739\n",
      "Epoch 14/500\n",
      " - 0s - loss: 3.0797 - acc: 0.1739\n",
      "Epoch 15/500\n",
      " - 0s - loss: 3.0787 - acc: 0.1739\n",
      "Epoch 16/500\n",
      " - 0s - loss: 3.0776 - acc: 0.1739\n",
      "Epoch 17/500\n",
      " - 0s - loss: 3.0766 - acc: 0.1739\n",
      "Epoch 18/500\n",
      " - 0s - loss: 3.0755 - acc: 0.1739\n",
      "Epoch 19/500\n",
      " - 0s - loss: 3.0744 - acc: 0.1739\n",
      "Epoch 20/500\n",
      " - 0s - loss: 3.0732 - acc: 0.1739\n",
      "Epoch 21/500\n",
      " - 0s - loss: 3.0720 - acc: 0.1739\n",
      "Epoch 22/500\n",
      " - 0s - loss: 3.0708 - acc: 0.1739\n",
      "Epoch 23/500\n",
      " - 0s - loss: 3.0695 - acc: 0.1739\n",
      "Epoch 24/500\n",
      " - 0s - loss: 3.0682 - acc: 0.1739\n",
      "Epoch 25/500\n",
      " - 0s - loss: 3.0669 - acc: 0.1739\n",
      "Epoch 26/500\n",
      " - 0s - loss: 3.0655 - acc: 0.1739\n",
      "Epoch 27/500\n",
      " - 0s - loss: 3.0640 - acc: 0.1739\n",
      "Epoch 28/500\n",
      " - 0s - loss: 3.0625 - acc: 0.1739\n",
      "Epoch 29/500\n",
      " - 0s - loss: 3.0609 - acc: 0.1739\n",
      "Epoch 30/500\n",
      " - 0s - loss: 3.0593 - acc: 0.1739\n",
      "Epoch 31/500\n",
      " - 0s - loss: 3.0576 - acc: 0.1739\n",
      "Epoch 32/500\n",
      " - 0s - loss: 3.0558 - acc: 0.1739\n",
      "Epoch 33/500\n",
      " - 0s - loss: 3.0540 - acc: 0.1739\n",
      "Epoch 34/500\n",
      " - 0s - loss: 3.0521 - acc: 0.1739\n",
      "Epoch 35/500\n",
      " - 0s - loss: 3.0501 - acc: 0.1739\n",
      "Epoch 36/500\n",
      " - 0s - loss: 3.0481 - acc: 0.1739\n",
      "Epoch 37/500\n",
      " - 0s - loss: 3.0459 - acc: 0.1739\n",
      "Epoch 38/500\n",
      " - 0s - loss: 3.0437 - acc: 0.1739\n",
      "Epoch 39/500\n",
      " - 0s - loss: 3.0414 - acc: 0.1739\n",
      "Epoch 40/500\n",
      " - 0s - loss: 3.0390 - acc: 0.1739\n",
      "Epoch 41/500\n",
      " - 0s - loss: 3.0366 - acc: 0.1739\n",
      "Epoch 42/500\n",
      " - 0s - loss: 3.0340 - acc: 0.1739\n",
      "Epoch 43/500\n",
      " - 0s - loss: 3.0313 - acc: 0.1739\n",
      "Epoch 44/500\n",
      " - 0s - loss: 3.0285 - acc: 0.1739\n",
      "Epoch 45/500\n",
      " - 0s - loss: 3.0256 - acc: 0.1739\n",
      "Epoch 46/500\n",
      " - 0s - loss: 3.0225 - acc: 0.1739\n",
      "Epoch 47/500\n",
      " - 0s - loss: 3.0194 - acc: 0.1739\n",
      "Epoch 48/500\n",
      " - 0s - loss: 3.0161 - acc: 0.1739\n",
      "Epoch 49/500\n",
      " - 0s - loss: 3.0127 - acc: 0.1739\n",
      "Epoch 50/500\n",
      " - 0s - loss: 3.0092 - acc: 0.1739\n",
      "Epoch 51/500\n",
      " - 0s - loss: 3.0055 - acc: 0.1739\n",
      "Epoch 52/500\n",
      " - 0s - loss: 3.0017 - acc: 0.1739\n",
      "Epoch 53/500\n",
      " - 0s - loss: 2.9977 - acc: 0.1739\n",
      "Epoch 54/500\n",
      " - 0s - loss: 2.9935 - acc: 0.1739\n",
      "Epoch 55/500\n",
      " - 0s - loss: 2.9892 - acc: 0.1739\n",
      "Epoch 56/500\n",
      " - 0s - loss: 2.9847 - acc: 0.1739\n",
      "Epoch 57/500\n",
      " - 0s - loss: 2.9801 - acc: 0.1739\n",
      "Epoch 58/500\n",
      " - 0s - loss: 2.9752 - acc: 0.1739\n",
      "Epoch 59/500\n",
      " - 0s - loss: 2.9702 - acc: 0.1739\n",
      "Epoch 60/500\n",
      " - 0s - loss: 2.9650 - acc: 0.1739\n",
      "Epoch 61/500\n",
      " - 0s - loss: 2.9595 - acc: 0.1739\n",
      "Epoch 62/500\n",
      " - 0s - loss: 2.9539 - acc: 0.1739\n",
      "Epoch 63/500\n",
      " - 0s - loss: 2.9480 - acc: 0.1739\n",
      "Epoch 64/500\n",
      " - 0s - loss: 2.9419 - acc: 0.1739\n",
      "Epoch 65/500\n",
      " - 0s - loss: 2.9355 - acc: 0.1739\n",
      "Epoch 66/500\n",
      " - 0s - loss: 2.9290 - acc: 0.1739\n",
      "Epoch 67/500\n",
      " - 0s - loss: 2.9221 - acc: 0.1739\n",
      "Epoch 68/500\n",
      " - 0s - loss: 2.9150 - acc: 0.1739\n",
      "Epoch 69/500\n",
      " - 0s - loss: 2.9077 - acc: 0.1739\n",
      "Epoch 70/500\n",
      " - 0s - loss: 2.9000 - acc: 0.1739\n",
      "Epoch 71/500\n",
      " - 0s - loss: 2.8921 - acc: 0.1739\n",
      "Epoch 72/500\n",
      " - 0s - loss: 2.8838 - acc: 0.1739\n",
      "Epoch 73/500\n",
      " - 0s - loss: 2.8753 - acc: 0.1739\n",
      "Epoch 74/500\n",
      " - 0s - loss: 2.8665 - acc: 0.1739\n",
      "Epoch 75/500\n",
      " - 0s - loss: 2.8573 - acc: 0.1739\n",
      "Epoch 76/500\n",
      " - 0s - loss: 2.8478 - acc: 0.1739\n",
      "Epoch 77/500\n",
      " - 0s - loss: 2.8379 - acc: 0.1739\n",
      "Epoch 78/500\n",
      " - 0s - loss: 2.8278 - acc: 0.1739\n",
      "Epoch 79/500\n",
      " - 0s - loss: 2.8172 - acc: 0.1739\n",
      "Epoch 80/500\n",
      " - 0s - loss: 2.8063 - acc: 0.1739\n",
      "Epoch 81/500\n",
      " - 0s - loss: 2.7950 - acc: 0.1739\n",
      "Epoch 82/500\n",
      " - 0s - loss: 2.7834 - acc: 0.2174\n",
      "Epoch 83/500\n",
      " - 0s - loss: 2.7713 - acc: 0.2174\n",
      "Epoch 84/500\n",
      " - 0s - loss: 2.7589 - acc: 0.2174\n",
      "Epoch 85/500\n",
      " - 0s - loss: 2.7461 - acc: 0.2174\n",
      "Epoch 86/500\n",
      " - 0s - loss: 2.7328 - acc: 0.2609\n",
      "Epoch 87/500\n",
      " - 0s - loss: 2.7192 - acc: 0.2609\n",
      "Epoch 88/500\n",
      " - 0s - loss: 2.7051 - acc: 0.2609\n",
      "Epoch 89/500\n",
      " - 0s - loss: 2.6907 - acc: 0.3043\n",
      "Epoch 90/500\n",
      " - 0s - loss: 2.6758 - acc: 0.2609\n",
      "Epoch 91/500\n",
      " - 0s - loss: 2.6605 - acc: 0.2609\n",
      "Epoch 92/500\n",
      " - 0s - loss: 2.6448 - acc: 0.2609\n",
      "Epoch 93/500\n",
      " - 0s - loss: 2.6286 - acc: 0.2609\n",
      "Epoch 94/500\n",
      " - 0s - loss: 2.6121 - acc: 0.2609\n",
      "Epoch 95/500\n",
      " - 0s - loss: 2.5951 - acc: 0.2609\n",
      "Epoch 96/500\n",
      " - 0s - loss: 2.5777 - acc: 0.2609\n",
      "Epoch 97/500\n",
      " - 0s - loss: 2.5600 - acc: 0.3043\n",
      "Epoch 98/500\n",
      " - 0s - loss: 2.5418 - acc: 0.3043\n",
      "Epoch 99/500\n",
      " - 0s - loss: 2.5232 - acc: 0.3043\n",
      "Epoch 100/500\n",
      " - 0s - loss: 2.5042 - acc: 0.3043\n",
      "Epoch 101/500\n",
      " - 0s - loss: 2.4849 - acc: 0.3043\n",
      "Epoch 102/500\n",
      " - 0s - loss: 2.4652 - acc: 0.3043\n",
      "Epoch 103/500\n",
      " - 0s - loss: 2.4451 - acc: 0.3043\n",
      "Epoch 104/500\n",
      " - 0s - loss: 2.4246 - acc: 0.3043\n",
      "Epoch 105/500\n",
      " - 0s - loss: 2.4039 - acc: 0.3043\n",
      "Epoch 106/500\n",
      " - 0s - loss: 2.3827 - acc: 0.3043\n",
      "Epoch 107/500\n",
      " - 0s - loss: 2.3614 - acc: 0.3478\n",
      "Epoch 108/500\n",
      " - 0s - loss: 2.3398 - acc: 0.3478\n",
      "Epoch 109/500\n",
      " - 0s - loss: 2.3179 - acc: 0.3478\n",
      "Epoch 110/500\n",
      " - 0s - loss: 2.2957 - acc: 0.3478\n",
      "Epoch 111/500\n",
      " - 0s - loss: 2.2733 - acc: 0.3478\n",
      "Epoch 112/500\n",
      " - 0s - loss: 2.2507 - acc: 0.3478\n",
      "Epoch 113/500\n",
      " - 0s - loss: 2.2279 - acc: 0.3478\n",
      "Epoch 114/500\n",
      " - 0s - loss: 2.2049 - acc: 0.3478\n",
      "Epoch 115/500\n",
      " - 0s - loss: 2.1818 - acc: 0.3478\n",
      "Epoch 116/500\n",
      " - 0s - loss: 2.1585 - acc: 0.3478\n",
      "Epoch 117/500\n",
      " - 0s - loss: 2.1351 - acc: 0.3478\n",
      "Epoch 118/500\n",
      " - 0s - loss: 2.1115 - acc: 0.3478\n",
      "Epoch 119/500\n",
      " - 0s - loss: 2.0877 - acc: 0.3478\n",
      "Epoch 120/500\n",
      " - 0s - loss: 2.0640 - acc: 0.4348\n",
      "Epoch 121/500\n",
      " - 0s - loss: 2.0401 - acc: 0.4348\n",
      "Epoch 122/500\n",
      " - 0s - loss: 2.0162 - acc: 0.4348\n",
      "Epoch 123/500\n",
      " - 0s - loss: 1.9922 - acc: 0.4783\n",
      "Epoch 124/500\n",
      " - 0s - loss: 1.9681 - acc: 0.4783\n",
      "Epoch 125/500\n",
      " - 0s - loss: 1.9440 - acc: 0.4783\n",
      "Epoch 126/500\n",
      " - 0s - loss: 1.9199 - acc: 0.5217\n",
      "Epoch 127/500\n",
      " - 0s - loss: 1.8957 - acc: 0.5652\n",
      "Epoch 128/500\n",
      " - 0s - loss: 1.8715 - acc: 0.5652\n",
      "Epoch 129/500\n",
      " - 0s - loss: 1.8474 - acc: 0.5652\n",
      "Epoch 130/500\n",
      " - 0s - loss: 1.8232 - acc: 0.5652\n",
      "Epoch 131/500\n",
      " - 0s - loss: 1.7990 - acc: 0.5652\n",
      "Epoch 132/500\n",
      " - 0s - loss: 1.7749 - acc: 0.6087\n",
      "Epoch 133/500\n",
      " - 0s - loss: 1.7507 - acc: 0.6522\n",
      "Epoch 134/500\n",
      " - 0s - loss: 1.7266 - acc: 0.6522\n",
      "Epoch 135/500\n",
      " - 0s - loss: 1.7025 - acc: 0.6522\n",
      "Epoch 136/500\n",
      " - 0s - loss: 1.6784 - acc: 0.6522\n",
      "Epoch 137/500\n",
      " - 0s - loss: 1.6544 - acc: 0.6522\n",
      "Epoch 138/500\n",
      " - 0s - loss: 1.6304 - acc: 0.6522\n",
      "Epoch 139/500\n",
      " - 0s - loss: 1.6064 - acc: 0.6522\n",
      "Epoch 140/500\n",
      " - 0s - loss: 1.5825 - acc: 0.6522\n",
      "Epoch 141/500\n",
      " - 0s - loss: 1.5585 - acc: 0.6522\n",
      "Epoch 142/500\n",
      " - 0s - loss: 1.5347 - acc: 0.6522\n",
      "Epoch 143/500\n",
      " - 0s - loss: 1.5109 - acc: 0.6522\n",
      "Epoch 144/500\n",
      " - 0s - loss: 1.4872 - acc: 0.6522\n",
      "Epoch 145/500\n",
      " - 0s - loss: 1.4636 - acc: 0.6957\n",
      "Epoch 146/500\n",
      " - 0s - loss: 1.4400 - acc: 0.7391\n",
      "Epoch 147/500\n",
      " - 0s - loss: 1.4165 - acc: 0.7391\n",
      "Epoch 148/500\n",
      " - 0s - loss: 1.3929 - acc: 0.7826\n",
      "Epoch 149/500\n",
      " - 0s - loss: 1.3694 - acc: 0.8261\n",
      "Epoch 150/500\n",
      " - 0s - loss: 1.3461 - acc: 0.8261\n",
      "Epoch 151/500\n",
      " - 0s - loss: 1.3229 - acc: 0.8261\n",
      "Epoch 152/500\n",
      " - 0s - loss: 1.2997 - acc: 0.9130\n",
      "Epoch 153/500\n",
      " - 0s - loss: 1.2766 - acc: 0.9130\n",
      "Epoch 154/500\n",
      " - 0s - loss: 1.2536 - acc: 0.9130\n",
      "Epoch 155/500\n",
      " - 0s - loss: 1.2308 - acc: 0.9130\n",
      "Epoch 156/500\n",
      " - 0s - loss: 1.2080 - acc: 0.9130\n",
      "Epoch 157/500\n",
      " - 0s - loss: 1.1853 - acc: 0.9130\n",
      "Epoch 158/500\n",
      " - 0s - loss: 1.1627 - acc: 0.9130\n",
      "Epoch 159/500\n",
      " - 0s - loss: 1.1402 - acc: 0.9130\n",
      "Epoch 160/500\n",
      " - 0s - loss: 1.1179 - acc: 0.9130\n",
      "Epoch 161/500\n",
      " - 0s - loss: 1.0956 - acc: 0.9130\n",
      "Epoch 162/500\n",
      " - 0s - loss: 1.0736 - acc: 0.9130\n",
      "Epoch 163/500\n",
      " - 0s - loss: 1.0516 - acc: 0.9130\n",
      "Epoch 164/500\n",
      " - 0s - loss: 1.0299 - acc: 0.9130\n",
      "Epoch 165/500\n",
      " - 0s - loss: 1.0082 - acc: 0.9130\n",
      "Epoch 166/500\n",
      " - 0s - loss: 0.9867 - acc: 0.9565\n",
      "Epoch 167/500\n",
      " - 0s - loss: 0.9654 - acc: 0.9565\n",
      "Epoch 168/500\n",
      " - 0s - loss: 0.9443 - acc: 0.9565\n",
      "Epoch 169/500\n",
      " - 0s - loss: 0.9235 - acc: 0.9565\n",
      "Epoch 170/500\n",
      " - 0s - loss: 0.9028 - acc: 0.9565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/500\n",
      " - 0s - loss: 0.8823 - acc: 0.9565\n",
      "Epoch 172/500\n",
      " - 0s - loss: 0.8620 - acc: 0.9565\n",
      "Epoch 173/500\n",
      " - 0s - loss: 0.8419 - acc: 0.9565\n",
      "Epoch 174/500\n",
      " - 0s - loss: 0.8222 - acc: 0.9565\n",
      "Epoch 175/500\n",
      " - 0s - loss: 0.8026 - acc: 0.9565\n",
      "Epoch 176/500\n",
      " - 0s - loss: 0.7833 - acc: 0.9565\n",
      "Epoch 177/500\n",
      " - 0s - loss: 0.7643 - acc: 0.9565\n",
      "Epoch 178/500\n",
      " - 0s - loss: 0.7455 - acc: 0.9565\n",
      "Epoch 179/500\n",
      " - 0s - loss: 0.7270 - acc: 0.9565\n",
      "Epoch 180/500\n",
      " - 0s - loss: 0.7089 - acc: 0.9565\n",
      "Epoch 181/500\n",
      " - 0s - loss: 0.6911 - acc: 0.9565\n",
      "Epoch 182/500\n",
      " - 0s - loss: 0.6736 - acc: 0.9565\n",
      "Epoch 183/500\n",
      " - 0s - loss: 0.6565 - acc: 0.9565\n",
      "Epoch 184/500\n",
      " - 0s - loss: 0.6396 - acc: 0.9565\n",
      "Epoch 185/500\n",
      " - 0s - loss: 0.6230 - acc: 0.9565\n",
      "Epoch 186/500\n",
      " - 0s - loss: 0.6068 - acc: 0.9565\n",
      "Epoch 187/500\n",
      " - 0s - loss: 0.5910 - acc: 0.9565\n",
      "Epoch 188/500\n",
      " - 0s - loss: 0.5756 - acc: 0.9565\n",
      "Epoch 189/500\n",
      " - 0s - loss: 0.5606 - acc: 0.9565\n",
      "Epoch 190/500\n",
      " - 0s - loss: 0.5459 - acc: 0.9565\n",
      "Epoch 191/500\n",
      " - 0s - loss: 0.5316 - acc: 0.9565\n",
      "Epoch 192/500\n",
      " - 0s - loss: 0.5176 - acc: 0.9565\n",
      "Epoch 193/500\n",
      " - 0s - loss: 0.5040 - acc: 0.9565\n",
      "Epoch 194/500\n",
      " - 0s - loss: 0.4907 - acc: 0.9565\n",
      "Epoch 195/500\n",
      " - 0s - loss: 0.4778 - acc: 0.9565\n",
      "Epoch 196/500\n",
      " - 0s - loss: 0.4653 - acc: 0.9565\n",
      "Epoch 197/500\n",
      " - 0s - loss: 0.4531 - acc: 0.9565\n",
      "Epoch 198/500\n",
      " - 0s - loss: 0.4413 - acc: 0.9565\n",
      "Epoch 199/500\n",
      " - 0s - loss: 0.4299 - acc: 0.9565\n",
      "Epoch 200/500\n",
      " - 0s - loss: 0.4188 - acc: 0.9565\n",
      "Epoch 201/500\n",
      " - 0s - loss: 0.4080 - acc: 0.9565\n",
      "Epoch 202/500\n",
      " - 0s - loss: 0.3975 - acc: 0.9565\n",
      "Epoch 203/500\n",
      " - 0s - loss: 0.3874 - acc: 0.9565\n",
      "Epoch 204/500\n",
      " - 0s - loss: 0.3776 - acc: 0.9565\n",
      "Epoch 205/500\n",
      " - 0s - loss: 0.3681 - acc: 0.9565\n",
      "Epoch 206/500\n",
      " - 0s - loss: 0.3589 - acc: 0.9565\n",
      "Epoch 207/500\n",
      " - 0s - loss: 0.3500 - acc: 0.9565\n",
      "Epoch 208/500\n",
      " - 0s - loss: 0.3414 - acc: 0.9565\n",
      "Epoch 209/500\n",
      " - 0s - loss: 0.3330 - acc: 0.9565\n",
      "Epoch 210/500\n",
      " - 0s - loss: 0.3249 - acc: 0.9565\n",
      "Epoch 211/500\n",
      " - 0s - loss: 0.3171 - acc: 0.9565\n",
      "Epoch 212/500\n",
      " - 0s - loss: 0.3096 - acc: 0.9565\n",
      "Epoch 213/500\n",
      " - 0s - loss: 0.3023 - acc: 0.9565\n",
      "Epoch 214/500\n",
      " - 0s - loss: 0.2952 - acc: 0.9565\n",
      "Epoch 215/500\n",
      " - 0s - loss: 0.2884 - acc: 0.9565\n",
      "Epoch 216/500\n",
      " - 0s - loss: 0.2819 - acc: 0.9565\n",
      "Epoch 217/500\n",
      " - 0s - loss: 0.2756 - acc: 0.9565\n",
      "Epoch 218/500\n",
      " - 0s - loss: 0.2695 - acc: 0.9565\n",
      "Epoch 219/500\n",
      " - 0s - loss: 0.2636 - acc: 0.9565\n",
      "Epoch 220/500\n",
      " - 0s - loss: 0.2579 - acc: 0.9565\n",
      "Epoch 221/500\n",
      " - 0s - loss: 0.2524 - acc: 0.9565\n",
      "Epoch 222/500\n",
      " - 0s - loss: 0.2471 - acc: 0.9565\n",
      "Epoch 223/500\n",
      " - 0s - loss: 0.2419 - acc: 0.9565\n",
      "Epoch 224/500\n",
      " - 0s - loss: 0.2369 - acc: 0.9565\n",
      "Epoch 225/500\n",
      " - 0s - loss: 0.2321 - acc: 0.9565\n",
      "Epoch 226/500\n",
      " - 0s - loss: 0.2274 - acc: 0.9565\n",
      "Epoch 227/500\n",
      " - 0s - loss: 0.2229 - acc: 0.9565\n",
      "Epoch 228/500\n",
      " - 0s - loss: 0.2185 - acc: 0.9565\n",
      "Epoch 229/500\n",
      " - 0s - loss: 0.2143 - acc: 0.9565\n",
      "Epoch 230/500\n",
      " - 0s - loss: 0.2102 - acc: 0.9565\n",
      "Epoch 231/500\n",
      " - 0s - loss: 0.2063 - acc: 0.9565\n",
      "Epoch 232/500\n",
      " - 0s - loss: 0.2025 - acc: 0.9565\n",
      "Epoch 233/500\n",
      " - 0s - loss: 0.1988 - acc: 0.9565\n",
      "Epoch 234/500\n",
      " - 0s - loss: 0.1952 - acc: 0.9565\n",
      "Epoch 235/500\n",
      " - 0s - loss: 0.1918 - acc: 0.9565\n",
      "Epoch 236/500\n",
      " - 0s - loss: 0.1884 - acc: 0.9565\n",
      "Epoch 237/500\n",
      " - 0s - loss: 0.1852 - acc: 0.9565\n",
      "Epoch 238/500\n",
      " - 0s - loss: 0.1821 - acc: 0.9565\n",
      "Epoch 239/500\n",
      " - 0s - loss: 0.1791 - acc: 0.9565\n",
      "Epoch 240/500\n",
      " - 0s - loss: 0.1762 - acc: 0.9565\n",
      "Epoch 241/500\n",
      " - 0s - loss: 0.1734 - acc: 0.9565\n",
      "Epoch 242/500\n",
      " - 0s - loss: 0.1707 - acc: 0.9565\n",
      "Epoch 243/500\n",
      " - 0s - loss: 0.1681 - acc: 0.9565\n",
      "Epoch 244/500\n",
      " - 0s - loss: 0.1656 - acc: 0.9565\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.1631 - acc: 0.9565\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.1607 - acc: 0.9565\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.1584 - acc: 0.9565\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.1562 - acc: 0.9565\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.1541 - acc: 0.9565\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.1520 - acc: 0.9565\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.1500 - acc: 0.9565\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.1480 - acc: 0.9565\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.1461 - acc: 0.9565\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.1443 - acc: 0.9565\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.1425 - acc: 0.9565\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.1408 - acc: 0.9565\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.1391 - acc: 0.9565\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.1375 - acc: 0.9565\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.1360 - acc: 0.9565\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.1345 - acc: 0.9565\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.1330 - acc: 0.9565\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.1316 - acc: 0.9565\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.1303 - acc: 0.9565\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.1290 - acc: 0.9565\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.1277 - acc: 0.9565\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.1264 - acc: 0.9565\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.1252 - acc: 0.9565\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.1241 - acc: 0.9565\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.1229 - acc: 0.9565\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.1218 - acc: 0.9565\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.1207 - acc: 0.9565\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.1197 - acc: 0.9565\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.1187 - acc: 0.9565\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.1177 - acc: 0.9565\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.1168 - acc: 0.9565\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.1159 - acc: 0.9565\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.1150 - acc: 0.9565\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.1141 - acc: 0.9565\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.1133 - acc: 0.9565\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.1124 - acc: 0.9565\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.1116 - acc: 0.9565\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.1109 - acc: 0.9565\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.1101 - acc: 0.9565\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.1094 - acc: 0.9565\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.1086 - acc: 0.9565\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.1079 - acc: 0.9565\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.1073 - acc: 0.9565\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.1066 - acc: 0.9565\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.1059 - acc: 0.9565\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.1053 - acc: 0.9565\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.1047 - acc: 0.9565\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.1041 - acc: 0.9565\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.1035 - acc: 0.9565\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.1029 - acc: 0.9565\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.1023 - acc: 0.9565\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.1018 - acc: 0.9565\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.1013 - acc: 0.9565\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.1007 - acc: 0.9565\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.1002 - acc: 0.9565\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.0997 - acc: 0.9565\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.0992 - acc: 0.9565\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.0988 - acc: 0.9565\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.0983 - acc: 0.9565\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.0978 - acc: 0.9565\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.0974 - acc: 0.9565\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.0969 - acc: 0.9565\n",
      "Epoch 307/500\n",
      " - 0s - loss: 0.0965 - acc: 0.9565\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.0961 - acc: 0.9565\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.0957 - acc: 0.9565\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.0953 - acc: 0.9565\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.0949 - acc: 0.9565\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.0945 - acc: 0.9565\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.0941 - acc: 0.9565\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.0938 - acc: 0.9565\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.0934 - acc: 0.9565\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.0930 - acc: 0.9565\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.0927 - acc: 0.9565\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.0923 - acc: 0.9565\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.0920 - acc: 0.9565\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.0917 - acc: 0.9565\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.0913 - acc: 0.9565\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.0910 - acc: 0.9565\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.0907 - acc: 0.9565\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.0904 - acc: 0.9565\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.0901 - acc: 0.9565\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.0898 - acc: 0.9565\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.0895 - acc: 0.9565\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.0892 - acc: 0.9565\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.0889 - acc: 0.9565\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.0887 - acc: 0.9565\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.0884 - acc: 0.9565\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.0881 - acc: 0.9565\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.0879 - acc: 0.9565\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.0876 - acc: 0.9565\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.0874 - acc: 0.9565\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.0871 - acc: 0.9565\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.0869 - acc: 0.9565\n",
      "Epoch 338/500\n",
      " - 0s - loss: 0.0866 - acc: 0.9565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/500\n",
      " - 0s - loss: 0.0864 - acc: 0.9565\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.0861 - acc: 0.9565\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.0859 - acc: 0.9565\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.0857 - acc: 0.9565\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.0855 - acc: 0.9565\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.0852 - acc: 0.9565\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.0850 - acc: 0.9565\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.0848 - acc: 0.9565\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.0846 - acc: 0.9565\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.0844 - acc: 0.9565\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.0842 - acc: 0.9565\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.0840 - acc: 0.9565\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.0838 - acc: 0.9565\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.0836 - acc: 0.9565\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.0834 - acc: 0.9565\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.0832 - acc: 0.9565\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.0830 - acc: 0.9565\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.0828 - acc: 0.9565\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.0827 - acc: 0.9565\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.0825 - acc: 0.9565\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.0823 - acc: 0.9565\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.0821 - acc: 0.9565\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.0819 - acc: 0.9565\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.0818 - acc: 0.9565\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.0816 - acc: 0.9565\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.0814 - acc: 0.9565\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.0813 - acc: 0.9565\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.0811 - acc: 0.9565\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.0810 - acc: 0.9565\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.0808 - acc: 0.9565\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.0806 - acc: 0.9565\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.0805 - acc: 0.9565\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.0803 - acc: 0.9565\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.0802 - acc: 0.9565\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.0800 - acc: 0.9565\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.0799 - acc: 0.9565\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.0798 - acc: 0.9565\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.0796 - acc: 0.9565\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.0795 - acc: 0.9565\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.0793 - acc: 0.9565\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.0792 - acc: 0.9565\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.0791 - acc: 0.9565\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.0789 - acc: 0.9565\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.0788 - acc: 0.9565\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.0787 - acc: 0.9565\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.0785 - acc: 0.9565\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.0784 - acc: 0.9565\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.0783 - acc: 0.9565\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.0782 - acc: 0.9565\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.0780 - acc: 0.9565\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.0779 - acc: 0.9565\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.0778 - acc: 0.9565\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.0777 - acc: 0.9565\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.0776 - acc: 0.9565\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.0774 - acc: 0.9565\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.0773 - acc: 0.9565\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.0772 - acc: 0.9565\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.0771 - acc: 0.9565\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.0770 - acc: 0.9565\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.0769 - acc: 0.9565\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.0768 - acc: 0.9565\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.0767 - acc: 0.9565\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.0765 - acc: 0.9565\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.0764 - acc: 0.9565\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.0763 - acc: 0.9565\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.0762 - acc: 0.9565\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.0761 - acc: 0.9565\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.0760 - acc: 0.9565\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.0759 - acc: 0.9565\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.0758 - acc: 0.9565\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.0757 - acc: 0.9565\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.0756 - acc: 0.9565\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.0755 - acc: 0.9565\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.0754 - acc: 0.9565\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.0753 - acc: 0.9565\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.0753 - acc: 0.9565\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.0752 - acc: 0.9565\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.0751 - acc: 0.9565\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.0750 - acc: 0.9565\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.0749 - acc: 0.9565\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.0748 - acc: 0.9565\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.0747 - acc: 0.9565\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.0746 - acc: 0.9565\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.0745 - acc: 0.9565\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.0745 - acc: 0.9565\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.0744 - acc: 0.9565\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.0743 - acc: 0.9565\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.0742 - acc: 0.9565\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.0741 - acc: 0.9565\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.0740 - acc: 0.9565\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.0740 - acc: 0.9565\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.0739 - acc: 0.9565\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.0738 - acc: 0.9565\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.0737 - acc: 0.9565\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.0736 - acc: 0.9565\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.0736 - acc: 0.9565\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.0735 - acc: 0.9565\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.0734 - acc: 0.9565\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.0733 - acc: 0.9565\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.0733 - acc: 0.9565\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.0732 - acc: 0.9565\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.0731 - acc: 0.9565\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.0730 - acc: 0.9565\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.0730 - acc: 0.9565\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.0729 - acc: 0.9565\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.0728 - acc: 0.9565\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.0728 - acc: 0.9565\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.0727 - acc: 0.9565\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.0726 - acc: 0.9565\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.0726 - acc: 0.9565\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.0725 - acc: 0.9565\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.0724 - acc: 0.9565\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.0724 - acc: 0.9565\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.0723 - acc: 0.9565\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.0722 - acc: 0.9565\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.0722 - acc: 0.9565\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.0721 - acc: 0.9565\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.0720 - acc: 0.9565\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.0720 - acc: 0.9565\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.0719 - acc: 0.9565\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.0719 - acc: 0.9565\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.0718 - acc: 0.9565\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.0717 - acc: 0.9565\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.0717 - acc: 0.9565\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.0716 - acc: 0.9565\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.0716 - acc: 0.9565\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.0715 - acc: 0.9565\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.0714 - acc: 0.9565\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.0714 - acc: 0.9565\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.0713 - acc: 0.9565\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.0713 - acc: 0.9565\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.0712 - acc: 0.9565\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.0712 - acc: 0.9565\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.0711 - acc: 0.9565\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.0711 - acc: 0.9565\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.0710 - acc: 0.9565\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.0710 - acc: 0.9565\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.0709 - acc: 0.9565\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.0708 - acc: 0.9565\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.0708 - acc: 0.9565\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.0707 - acc: 0.9565\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.0707 - acc: 0.9565\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.0706 - acc: 0.9565\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.0706 - acc: 0.9565\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.0705 - acc: 0.9565\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.0705 - acc: 0.9565\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.0704 - acc: 0.9565\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.0704 - acc: 0.9565\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.0703 - acc: 0.9565\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.0703 - acc: 0.9565\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.0702 - acc: 0.9565\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.0702 - acc: 0.9565\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.0702 - acc: 0.9565\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.0701 - acc: 0.9565\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.0701 - acc: 0.9565\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.0700 - acc: 0.9565\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.0700 - acc: 0.9565\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.0699 - acc: 0.9565\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.0699 - acc: 0.9565\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.0698 - acc: 0.9565\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.0698 - acc: 0.9565\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.0697 - acc: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2220d538048>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "TaXvs6X0JEbV",
    "outputId": "4ded8a31-ac30-4e0d-f7d2-281d54bec15a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack and jill went up the hill\n",
      "And Jill went up the\n",
      "fell down and broke his crown and\n",
      "pail of water jack fell down and\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jack and', 5))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'And Jill', 3))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'fell down', 5))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'pail of', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-HVuMdcZJG1m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jo6v8YDQJRtP"
   },
   "source": [
    "# https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "next_word_prediction_simple.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
